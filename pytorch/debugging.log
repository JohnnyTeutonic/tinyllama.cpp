2025-04-25 23:03:39,775 - INFO - Config: {'architectures': ['LlamaForCausalLM'], 'attention_bias': False, 'bos_token_id': 1, 'eos_token_id': 2, 'hidden_act': 'silu', 'hidden_size': 2048, 'initializer_range': 0.02, 'intermediate_size': 5632, 'max_position_embeddings': 2048, 'model_type': 'llama', 'num_attention_heads': 32, 'num_hidden_layers': 22, 'num_key_value_heads': 4, 'pretraining_tp': 1, 'rms_norm_eps': 1e-05, 'rope_scaling': None, 'rope_theta': 10000.0, 'tie_word_embeddings': False, 'torch_dtype': 'bfloat16', 'transformers_version': '4.35.0', 'use_cache': True, 'vocab_size': 32000}
2025-04-25 23:03:46,901 - INFO - Loading model.embed_tokens.weight:
2025-04-25 23:03:46,902 - INFO -   - Tensor shape: torch.Size([32000, 2048]), dtype: torch.bfloat16
2025-04-25 23:03:46,902 - INFO -   - Param shape: torch.Size([32000, 2048]), dtype: torch.float32
2025-04-25 23:03:47,932 - INFO -   - Copied (Embedding). Param mean: -0.0000, std: 0.0149
2025-04-25 23:03:47,932 - INFO - Loading lm_head.weight:
2025-04-25 23:03:47,932 - INFO -   - Tensor shape: torch.Size([32000, 2048]), dtype: torch.bfloat16
2025-04-25 23:03:47,933 - INFO -   - Param shape: torch.Size([32000, 2048]), dtype: torch.float32
2025-04-25 23:03:48,967 - INFO -   - Copied (Output Head). Param mean: -0.0004, std: 0.0247
2025-04-25 23:03:48,967 - INFO - Loading model.norm.weight:
2025-04-25 23:03:48,968 - INFO -   - Tensor shape: torch.Size([2048]), dtype: torch.bfloat16
2025-04-25 23:03:48,968 - INFO -   - Param shape: torch.Size([2048]), dtype: torch.float32
2025-04-25 23:03:48,969 - INFO -   - Copied (Final Norm). Param mean: 1.9149, std: 0.1365
2025-04-25 23:03:48,969 - INFO - Loading model.layers.0.input_layernorm.weight:
2025-04-25 23:03:48,969 - INFO -   - Tensor shape: torch.Size([2048]), dtype: torch.bfloat16
2025-04-25 23:03:48,969 - INFO -   - Param shape: torch.Size([2048]), dtype: torch.float32
2025-04-25 23:03:48,970 - INFO -   - Copied. Param mean: 0.0058, std: 0.0460
2025-04-25 23:03:48,970 - INFO - Loading model.layers.0.post_attention_layernorm.weight:
2025-04-25 23:03:48,970 - INFO -   - Tensor shape: torch.Size([2048]), dtype: torch.bfloat16
2025-04-25 23:03:48,970 - INFO -   - Param shape: torch.Size([2048]), dtype: torch.float32
2025-04-25 23:03:48,970 - INFO -   - Copied. Param mean: 0.0746, std: 0.0331
2025-04-25 23:03:48,970 - INFO - Loading model.layers.0.self_attn.q_proj.weight:
2025-04-25 23:03:48,971 - INFO -   - Tensor shape: torch.Size([2048, 2048]), dtype: torch.bfloat16
2025-04-25 23:03:48,971 - INFO -   - Param shape: torch.Size([2048, 2048]), dtype: torch.float32
2025-04-25 23:03:49,031 - INFO -   - Copied. Param mean: -0.0000, std: 0.0164
2025-04-25 23:03:49,031 - INFO - Loading model.layers.0.self_attn.k_proj.weight:
2025-04-25 23:03:49,032 - INFO -   - Tensor shape: torch.Size([256, 2048]), dtype: torch.bfloat16
2025-04-25 23:03:49,032 - INFO -   - Param shape: torch.Size([256, 2048]), dtype: torch.float32
2025-04-25 23:03:49,050 - INFO -   - Copied. Param mean: -0.0001, std: 0.0318
2025-04-25 23:03:49,051 - INFO - Loading model.layers.0.self_attn.v_proj.weight:
2025-04-25 23:03:49,051 - INFO -   - Tensor shape: torch.Size([256, 2048]), dtype: torch.bfloat16
2025-04-25 23:03:49,051 - INFO -   - Param shape: torch.Size([256, 2048]), dtype: torch.float32
2025-04-25 23:03:49,062 - INFO -   - Copied. Param mean: 0.0000, std: 0.0110
2025-04-25 23:03:49,062 - INFO - Loading model.layers.0.self_attn.o_proj.weight:
2025-04-25 23:03:49,062 - INFO -   - Tensor shape: torch.Size([2048, 2048]), dtype: torch.bfloat16
2025-04-25 23:03:49,063 - INFO -   - Param shape: torch.Size([2048, 2048]), dtype: torch.float32
2025-04-25 23:03:49,128 - INFO -   - Copied. Param mean: 0.0000, std: 0.0083
2025-04-25 23:03:49,129 - INFO - Loading model.layers.0.mlp.gate_proj.weight:
2025-04-25 23:03:49,129 - INFO -   - Tensor shape: torch.Size([5632, 2048]), dtype: torch.bfloat16
2025-04-25 23:03:49,129 - INFO -   - Param shape: torch.Size([5632, 2048]), dtype: torch.float32
2025-04-25 23:03:49,312 - INFO -   - Copied. Param mean: -0.0000, std: 0.0166
2025-04-25 23:03:49,312 - INFO - Loading model.layers.0.mlp.up_proj.weight:
2025-04-25 23:03:49,312 - INFO -   - Tensor shape: torch.Size([5632, 2048]), dtype: torch.bfloat16
2025-04-25 23:03:49,312 - INFO -   - Param shape: torch.Size([5632, 2048]), dtype: torch.float32
2025-04-25 23:03:49,484 - INFO -   - Copied. Param mean: -0.0000, std: 0.0168
2025-04-25 23:03:49,484 - INFO - Loading model.layers.0.mlp.down_proj.weight:
2025-04-25 23:03:49,485 - INFO -   - Tensor shape: torch.Size([2048, 5632]), dtype: torch.bfloat16
2025-04-25 23:03:49,485 - INFO -   - Param shape: torch.Size([2048, 5632]), dtype: torch.float32
2025-04-25 23:03:49,647 - INFO -   - Copied. Param mean: 0.0000, std: 0.0166
2025-04-25 23:03:49,647 - INFO - Loading model.layers.1.input_layernorm.weight:
2025-04-25 23:03:49,647 - INFO -   - Tensor shape: torch.Size([2048]), dtype: torch.bfloat16
2025-04-25 23:03:49,648 - INFO -   - Param shape: torch.Size([2048]), dtype: torch.float32
2025-04-25 23:03:49,648 - INFO -   - Copied. Param mean: 0.0405, std: 0.0559
2025-04-25 23:03:49,648 - INFO - Loading model.layers.1.post_attention_layernorm.weight:
2025-04-25 23:03:49,648 - INFO -   - Tensor shape: torch.Size([2048]), dtype: torch.bfloat16
2025-04-25 23:03:49,649 - INFO -   - Param shape: torch.Size([2048]), dtype: torch.float32
2025-04-25 23:03:49,649 - INFO -   - Copied. Param mean: 0.1284, std: 0.0211
2025-04-25 23:03:49,649 - INFO - Loading model.layers.1.self_attn.q_proj.weight:
2025-04-25 23:03:49,649 - INFO -   - Tensor shape: torch.Size([2048, 2048]), dtype: torch.bfloat16
2025-04-25 23:03:49,649 - INFO -   - Param shape: torch.Size([2048, 2048]), dtype: torch.float32
2025-04-25 23:03:49,713 - INFO -   - Copied. Param mean: 0.0000, std: 0.0294
2025-04-25 23:03:49,713 - INFO - Loading model.layers.1.self_attn.k_proj.weight:
2025-04-25 23:03:49,713 - INFO -   - Tensor shape: torch.Size([256, 2048]), dtype: torch.bfloat16
2025-04-25 23:03:49,714 - INFO -   - Param shape: torch.Size([256, 2048]), dtype: torch.float32
2025-04-25 23:03:49,723 - INFO -   - Copied. Param mean: -0.0000, std: 0.0479
2025-04-25 23:03:49,723 - INFO - Loading model.layers.1.self_attn.v_proj.weight:
2025-04-25 23:03:49,723 - INFO -   - Tensor shape: torch.Size([256, 2048]), dtype: torch.bfloat16
2025-04-25 23:03:49,724 - INFO -   - Param shape: torch.Size([256, 2048]), dtype: torch.float32
2025-04-25 23:03:49,737 - INFO -   - Copied. Param mean: 0.0000, std: 0.0134
2025-04-25 23:03:49,738 - INFO - Loading model.layers.1.self_attn.o_proj.weight:
2025-04-25 23:03:49,738 - INFO -   - Tensor shape: torch.Size([2048, 2048]), dtype: torch.bfloat16
2025-04-25 23:03:49,738 - INFO -   - Param shape: torch.Size([2048, 2048]), dtype: torch.float32
2025-04-25 23:03:49,799 - INFO -   - Copied. Param mean: -0.0000, std: 0.0137
2025-04-25 23:03:49,800 - INFO - Loading model.layers.1.mlp.gate_proj.weight:
2025-04-25 23:03:49,800 - INFO -   - Tensor shape: torch.Size([5632, 2048]), dtype: torch.bfloat16
2025-04-25 23:03:49,800 - INFO -   - Param shape: torch.Size([5632, 2048]), dtype: torch.float32
2025-04-25 23:03:49,990 - INFO -   - Copied. Param mean: 0.0000, std: 0.0181
2025-04-25 23:03:49,990 - INFO - Loading model.layers.1.mlp.up_proj.weight:
2025-04-25 23:03:49,991 - INFO -   - Tensor shape: torch.Size([5632, 2048]), dtype: torch.bfloat16
2025-04-25 23:03:49,991 - INFO -   - Param shape: torch.Size([5632, 2048]), dtype: torch.float32
2025-04-25 23:03:50,164 - INFO -   - Copied. Param mean: -0.0000, std: 0.0173
2025-04-25 23:03:50,164 - INFO - Loading model.layers.1.mlp.down_proj.weight:
2025-04-25 23:03:50,165 - INFO -   - Tensor shape: torch.Size([2048, 5632]), dtype: torch.bfloat16
2025-04-25 23:03:50,165 - INFO -   - Param shape: torch.Size([2048, 5632]), dtype: torch.float32
2025-04-25 23:03:50,335 - INFO -   - Copied. Param mean: 0.0000, std: 0.0171
2025-04-25 23:03:50,335 - INFO - Loading model.layers.2.input_layernorm.weight:
2025-04-25 23:03:50,335 - INFO -   - Tensor shape: torch.Size([2048]), dtype: torch.bfloat16
2025-04-25 23:03:50,336 - INFO -   - Param shape: torch.Size([2048]), dtype: torch.float32
2025-04-25 23:03:50,336 - INFO -   - Copied. Param mean: 0.0846, std: 0.0684
2025-04-25 23:03:50,336 - INFO - Loading model.layers.2.post_attention_layernorm.weight:
2025-04-25 23:03:50,337 - INFO -   - Tensor shape: torch.Size([2048]), dtype: torch.bfloat16
2025-04-25 23:03:50,337 - INFO -   - Param shape: torch.Size([2048]), dtype: torch.float32
2025-04-25 23:03:50,337 - INFO -   - Copied. Param mean: 0.1674, std: 0.0219
2025-04-25 23:03:50,337 - INFO - Loading model.layers.2.self_attn.q_proj.weight:
2025-04-25 23:03:50,338 - INFO -   - Tensor shape: torch.Size([2048, 2048]), dtype: torch.bfloat16
2025-04-25 23:03:50,338 - INFO -   - Param shape: torch.Size([2048, 2048]), dtype: torch.float32
2025-04-25 23:03:50,402 - INFO -   - Copied. Param mean: 0.0000, std: 0.0322
2025-04-25 23:03:50,402 - INFO - Loading model.layers.2.self_attn.k_proj.weight:
2025-04-25 23:03:50,402 - INFO -   - Tensor shape: torch.Size([256, 2048]), dtype: torch.bfloat16
2025-04-25 23:03:50,402 - INFO -   - Param shape: torch.Size([256, 2048]), dtype: torch.float32
2025-04-25 23:03:50,423 - INFO -   - Copied. Param mean: 0.0001, std: 0.0542
2025-04-25 23:03:50,424 - INFO - Loading model.layers.2.self_attn.v_proj.weight:
2025-04-25 23:03:50,424 - INFO -   - Tensor shape: torch.Size([256, 2048]), dtype: torch.bfloat16
2025-04-25 23:03:50,424 - INFO -   - Param shape: torch.Size([256, 2048]), dtype: torch.float32
2025-04-25 23:03:50,443 - INFO -   - Copied. Param mean: -0.0000, std: 0.0118
2025-04-25 23:03:50,443 - INFO - Loading model.layers.2.self_attn.o_proj.weight:
2025-04-25 23:03:50,444 - INFO -   - Tensor shape: torch.Size([2048, 2048]), dtype: torch.bfloat16
2025-04-25 23:03:50,444 - INFO -   - Param shape: torch.Size([2048, 2048]), dtype: torch.float32
2025-04-25 23:03:50,504 - INFO -   - Copied. Param mean: -0.0000, std: 0.0141
2025-04-25 23:03:50,504 - INFO - Loading model.layers.2.mlp.gate_proj.weight:
2025-04-25 23:03:50,505 - INFO -   - Tensor shape: torch.Size([5632, 2048]), dtype: torch.bfloat16
2025-04-25 23:03:50,505 - INFO -   - Param shape: torch.Size([5632, 2048]), dtype: torch.float32
2025-04-25 23:03:50,676 - INFO -   - Copied. Param mean: -0.0000, std: 0.0185
2025-04-25 23:03:50,676 - INFO - Loading model.layers.2.mlp.up_proj.weight:
2025-04-25 23:03:50,676 - INFO -   - Tensor shape: torch.Size([5632, 2048]), dtype: torch.bfloat16
2025-04-25 23:03:50,677 - INFO -   - Param shape: torch.Size([5632, 2048]), dtype: torch.float32
2025-04-25 23:03:50,858 - INFO -   - Copied. Param mean: -0.0000, std: 0.0175
2025-04-25 23:03:50,858 - INFO - Loading model.layers.2.mlp.down_proj.weight:
2025-04-25 23:03:50,859 - INFO -   - Tensor shape: torch.Size([2048, 5632]), dtype: torch.bfloat16
2025-04-25 23:03:50,859 - INFO -   - Param shape: torch.Size([2048, 5632]), dtype: torch.float32
2025-04-25 23:03:51,055 - INFO -   - Copied. Param mean: 0.0000, std: 0.0174
2025-04-25 23:03:51,055 - INFO - Loading model.layers.3.input_layernorm.weight:
2025-04-25 23:03:51,056 - INFO -   - Tensor shape: torch.Size([2048]), dtype: torch.bfloat16
2025-04-25 23:03:51,056 - INFO -   - Param shape: torch.Size([2048]), dtype: torch.float32
2025-04-25 23:03:51,056 - INFO -   - Copied. Param mean: 0.2243, std: 0.0547
2025-04-25 23:03:51,056 - INFO - Loading model.layers.3.post_attention_layernorm.weight:
2025-04-25 23:03:51,057 - INFO -   - Tensor shape: torch.Size([2048]), dtype: torch.bfloat16
2025-04-25 23:03:51,057 - INFO -   - Param shape: torch.Size([2048]), dtype: torch.float32
2025-04-25 23:03:51,057 - INFO -   - Copied. Param mean: 0.1843, std: 0.0214
2025-04-25 23:03:51,058 - INFO - Loading model.layers.3.self_attn.q_proj.weight:
2025-04-25 23:03:51,058 - INFO -   - Tensor shape: torch.Size([2048, 2048]), dtype: torch.bfloat16
2025-04-25 23:03:51,058 - INFO -   - Param shape: torch.Size([2048, 2048]), dtype: torch.float32
2025-04-25 23:03:51,124 - INFO -   - Copied. Param mean: -0.0000, std: 0.0271
2025-04-25 23:03:51,124 - INFO - Loading model.layers.3.self_attn.k_proj.weight:
2025-04-25 23:03:51,125 - INFO -   - Tensor shape: torch.Size([256, 2048]), dtype: torch.bfloat16
2025-04-25 23:03:51,125 - INFO -   - Param shape: torch.Size([256, 2048]), dtype: torch.float32
2025-04-25 23:03:51,136 - INFO -   - Copied. Param mean: 0.0001, std: 0.0477
2025-04-25 23:03:51,136 - INFO - Loading model.layers.3.self_attn.v_proj.weight:
2025-04-25 23:03:51,137 - INFO -   - Tensor shape: torch.Size([256, 2048]), dtype: torch.bfloat16
2025-04-25 23:03:51,137 - INFO -   - Param shape: torch.Size([256, 2048]), dtype: torch.float32
2025-04-25 23:03:51,156 - INFO -   - Copied. Param mean: -0.0000, std: 0.0114
2025-04-25 23:03:51,157 - INFO - Loading model.layers.3.self_attn.o_proj.weight:
2025-04-25 23:03:51,157 - INFO -   - Tensor shape: torch.Size([2048, 2048]), dtype: torch.bfloat16
2025-04-25 23:03:51,157 - INFO -   - Param shape: torch.Size([2048, 2048]), dtype: torch.float32
2025-04-25 23:03:51,233 - INFO -   - Copied. Param mean: 0.0000, std: 0.0143
2025-04-25 23:03:51,233 - INFO - Loading model.layers.3.mlp.gate_proj.weight:
2025-04-25 23:03:51,233 - INFO -   - Tensor shape: torch.Size([5632, 2048]), dtype: torch.bfloat16
2025-04-25 23:03:51,234 - INFO -   - Param shape: torch.Size([5632, 2048]), dtype: torch.float32
2025-04-25 23:03:51,416 - INFO -   - Copied. Param mean: -0.0000, std: 0.0187
2025-04-25 23:03:51,417 - INFO - Loading model.layers.3.mlp.up_proj.weight:
2025-04-25 23:03:51,417 - INFO -   - Tensor shape: torch.Size([5632, 2048]), dtype: torch.bfloat16
2025-04-25 23:03:51,417 - INFO -   - Param shape: torch.Size([5632, 2048]), dtype: torch.float32
2025-04-25 23:03:51,599 - INFO -   - Copied. Param mean: -0.0000, std: 0.0174
2025-04-25 23:03:51,600 - INFO - Loading model.layers.3.mlp.down_proj.weight:
2025-04-25 23:03:51,600 - INFO -   - Tensor shape: torch.Size([2048, 5632]), dtype: torch.bfloat16
2025-04-25 23:03:51,600 - INFO -   - Param shape: torch.Size([2048, 5632]), dtype: torch.float32
2025-04-25 23:03:51,771 - INFO -   - Copied. Param mean: 0.0000, std: 0.0173
2025-04-25 23:03:51,772 - INFO - Loading model.layers.4.input_layernorm.weight:
2025-04-25 23:03:51,772 - INFO -   - Tensor shape: torch.Size([2048]), dtype: torch.bfloat16
2025-04-25 23:03:51,772 - INFO -   - Param shape: torch.Size([2048]), dtype: torch.float32
2025-04-25 23:03:51,772 - INFO -   - Copied. Param mean: 0.3199, std: 0.0582
2025-04-25 23:03:51,773 - INFO - Loading model.layers.4.post_attention_layernorm.weight:
2025-04-25 23:03:51,773 - INFO -   - Tensor shape: torch.Size([2048]), dtype: torch.bfloat16
2025-04-25 23:03:51,773 - INFO -   - Param shape: torch.Size([2048]), dtype: torch.float32
2025-04-25 23:03:51,773 - INFO -   - Copied. Param mean: 0.1978, std: 0.0238
2025-04-25 23:03:51,773 - INFO - Loading model.layers.4.self_attn.q_proj.weight:
2025-04-25 23:03:51,773 - INFO -   - Tensor shape: torch.Size([2048, 2048]), dtype: torch.bfloat16
2025-04-25 23:03:51,774 - INFO -   - Param shape: torch.Size([2048, 2048]), dtype: torch.float32
2025-04-25 23:03:51,835 - INFO -   - Copied. Param mean: 0.0000, std: 0.0260
2025-04-25 23:03:51,835 - INFO - Loading model.layers.4.self_attn.k_proj.weight:
2025-04-25 23:03:51,835 - INFO -   - Tensor shape: torch.Size([256, 2048]), dtype: torch.bfloat16
2025-04-25 23:03:51,835 - INFO -   - Param shape: torch.Size([256, 2048]), dtype: torch.float32
2025-04-25 23:03:51,848 - INFO -   - Copied. Param mean: 0.0000, std: 0.0490
2025-04-25 23:03:51,848 - INFO - Loading model.layers.4.self_attn.v_proj.weight:
2025-04-25 23:03:51,848 - INFO -   - Tensor shape: torch.Size([256, 2048]), dtype: torch.bfloat16
2025-04-25 23:03:51,849 - INFO -   - Param shape: torch.Size([256, 2048]), dtype: torch.float32
2025-04-25 23:03:51,859 - INFO -   - Copied. Param mean: 0.0000, std: 0.0101
2025-04-25 23:03:51,859 - INFO - Loading model.layers.4.self_attn.o_proj.weight:
2025-04-25 23:03:51,859 - INFO -   - Tensor shape: torch.Size([2048, 2048]), dtype: torch.bfloat16
2025-04-25 23:03:51,859 - INFO -   - Param shape: torch.Size([2048, 2048]), dtype: torch.float32
2025-04-25 23:03:51,919 - INFO -   - Copied. Param mean: -0.0000, std: 0.0140
2025-04-25 23:03:51,920 - INFO - Loading model.layers.4.mlp.gate_proj.weight:
2025-04-25 23:03:51,920 - INFO -   - Tensor shape: torch.Size([5632, 2048]), dtype: torch.bfloat16
2025-04-25 23:03:51,920 - INFO -   - Param shape: torch.Size([5632, 2048]), dtype: torch.float32
2025-04-25 23:03:52,088 - INFO -   - Copied. Param mean: -0.0000, std: 0.0190
2025-04-25 23:03:52,089 - INFO - Loading model.layers.4.mlp.up_proj.weight:
2025-04-25 23:03:52,089 - INFO -   - Tensor shape: torch.Size([5632, 2048]), dtype: torch.bfloat16
2025-04-25 23:03:52,089 - INFO -   - Param shape: torch.Size([5632, 2048]), dtype: torch.float32
2025-04-25 23:03:52,263 - INFO -   - Copied. Param mean: -0.0000, std: 0.0173
2025-04-25 23:03:52,263 - INFO - Loading model.layers.4.mlp.down_proj.weight:
2025-04-25 23:03:52,263 - INFO -   - Tensor shape: torch.Size([2048, 5632]), dtype: torch.bfloat16
2025-04-25 23:03:52,264 - INFO -   - Param shape: torch.Size([2048, 5632]), dtype: torch.float32
2025-04-25 23:03:52,427 - INFO -   - Copied. Param mean: -0.0000, std: 0.0173
2025-04-25 23:03:52,427 - INFO - Loading model.layers.5.input_layernorm.weight:
2025-04-25 23:03:52,427 - INFO -   - Tensor shape: torch.Size([2048]), dtype: torch.bfloat16
2025-04-25 23:03:52,428 - INFO -   - Param shape: torch.Size([2048]), dtype: torch.float32
2025-04-25 23:03:52,428 - INFO -   - Copied. Param mean: 0.2800, std: 0.0488
2025-04-25 23:03:52,428 - INFO - Loading model.layers.5.post_attention_layernorm.weight:
2025-04-25 23:03:52,428 - INFO -   - Tensor shape: torch.Size([2048]), dtype: torch.bfloat16
2025-04-25 23:03:52,428 - INFO -   - Param shape: torch.Size([2048]), dtype: torch.float32
2025-04-25 23:03:52,429 - INFO -   - Copied. Param mean: 0.2160, std: 0.0225
2025-04-25 23:03:52,429 - INFO - Loading model.layers.5.self_attn.q_proj.weight:
2025-04-25 23:03:52,429 - INFO -   - Tensor shape: torch.Size([2048, 2048]), dtype: torch.bfloat16
2025-04-25 23:03:52,429 - INFO -   - Param shape: torch.Size([2048, 2048]), dtype: torch.float32
2025-04-25 23:03:52,488 - INFO -   - Copied. Param mean: -0.0000, std: 0.0271
2025-04-25 23:03:52,488 - INFO - Loading model.layers.5.self_attn.k_proj.weight:
2025-04-25 23:03:52,488 - INFO -   - Tensor shape: torch.Size([256, 2048]), dtype: torch.bfloat16
2025-04-25 23:03:52,488 - INFO -   - Param shape: torch.Size([256, 2048]), dtype: torch.float32
2025-04-25 23:03:52,503 - INFO -   - Copied. Param mean: 0.0000, std: 0.0502
2025-04-25 23:03:52,503 - INFO - Loading model.layers.5.self_attn.v_proj.weight:
2025-04-25 23:03:52,503 - INFO -   - Tensor shape: torch.Size([256, 2048]), dtype: torch.bfloat16
2025-04-25 23:03:52,503 - INFO -   - Param shape: torch.Size([256, 2048]), dtype: torch.float32
2025-04-25 23:03:52,512 - INFO -   - Copied. Param mean: 0.0000, std: 0.0115
2025-04-25 23:03:52,512 - INFO - Loading model.layers.5.self_attn.o_proj.weight:
2025-04-25 23:03:52,512 - INFO -   - Tensor shape: torch.Size([2048, 2048]), dtype: torch.bfloat16
2025-04-25 23:03:52,512 - INFO -   - Param shape: torch.Size([2048, 2048]), dtype: torch.float32
2025-04-25 23:03:52,566 - INFO -   - Copied. Param mean: -0.0000, std: 0.0145
2025-04-25 23:03:52,567 - INFO - Loading model.layers.5.mlp.gate_proj.weight:
2025-04-25 23:03:52,567 - INFO -   - Tensor shape: torch.Size([5632, 2048]), dtype: torch.bfloat16
2025-04-25 23:03:52,567 - INFO -   - Param shape: torch.Size([5632, 2048]), dtype: torch.float32
2025-04-25 23:03:52,722 - INFO -   - Copied. Param mean: -0.0000, std: 0.0192
2025-04-25 23:03:52,723 - INFO - Loading model.layers.5.mlp.up_proj.weight:
2025-04-25 23:03:52,723 - INFO -   - Tensor shape: torch.Size([5632, 2048]), dtype: torch.bfloat16
2025-04-25 23:03:52,723 - INFO -   - Param shape: torch.Size([5632, 2048]), dtype: torch.float32
2025-04-25 23:03:52,883 - INFO -   - Copied. Param mean: 0.0000, std: 0.0174
2025-04-25 23:03:52,883 - INFO - Loading model.layers.5.mlp.down_proj.weight:
2025-04-25 23:03:52,884 - INFO -   - Tensor shape: torch.Size([2048, 5632]), dtype: torch.bfloat16
2025-04-25 23:03:52,884 - INFO -   - Param shape: torch.Size([2048, 5632]), dtype: torch.float32
2025-04-25 23:03:53,048 - INFO -   - Copied. Param mean: 0.0000, std: 0.0173
2025-04-25 23:03:53,048 - INFO - Loading model.layers.6.input_layernorm.weight:
2025-04-25 23:03:53,048 - INFO -   - Tensor shape: torch.Size([2048]), dtype: torch.bfloat16
2025-04-25 23:03:53,049 - INFO -   - Param shape: torch.Size([2048]), dtype: torch.float32
2025-04-25 23:03:53,049 - INFO -   - Copied. Param mean: 0.2680, std: 0.0792
2025-04-25 23:03:53,049 - INFO - Loading model.layers.6.post_attention_layernorm.weight:
2025-04-25 23:03:53,049 - INFO -   - Tensor shape: torch.Size([2048]), dtype: torch.bfloat16
2025-04-25 23:03:53,049 - INFO -   - Param shape: torch.Size([2048]), dtype: torch.float32
2025-04-25 23:03:53,049 - INFO -   - Copied. Param mean: 0.2251, std: 0.0219
2025-04-25 23:03:53,050 - INFO - Loading model.layers.6.self_attn.q_proj.weight:
2025-04-25 23:03:53,050 - INFO -   - Tensor shape: torch.Size([2048, 2048]), dtype: torch.bfloat16
2025-04-25 23:03:53,050 - INFO -   - Param shape: torch.Size([2048, 2048]), dtype: torch.float32
2025-04-25 23:03:53,110 - INFO -   - Copied. Param mean: 0.0000, std: 0.0263
2025-04-25 23:03:53,110 - INFO - Loading model.layers.6.self_attn.k_proj.weight:
2025-04-25 23:03:53,110 - INFO -   - Tensor shape: torch.Size([256, 2048]), dtype: torch.bfloat16
2025-04-25 23:03:53,110 - INFO -   - Param shape: torch.Size([256, 2048]), dtype: torch.float32
2025-04-25 23:03:53,125 - INFO -   - Copied. Param mean: 0.0001, std: 0.0471
2025-04-25 23:03:53,125 - INFO - Loading model.layers.6.self_attn.v_proj.weight:
2025-04-25 23:03:53,126 - INFO -   - Tensor shape: torch.Size([256, 2048]), dtype: torch.bfloat16
2025-04-25 23:03:53,126 - INFO -   - Param shape: torch.Size([256, 2048]), dtype: torch.float32
2025-04-25 23:03:53,140 - INFO -   - Copied. Param mean: -0.0000, std: 0.0113
2025-04-25 23:03:53,140 - INFO - Loading model.layers.6.self_attn.o_proj.weight:
2025-04-25 23:03:53,141 - INFO -   - Tensor shape: torch.Size([2048, 2048]), dtype: torch.bfloat16
2025-04-25 23:03:53,141 - INFO -   - Param shape: torch.Size([2048, 2048]), dtype: torch.float32
2025-04-25 23:03:53,209 - INFO -   - Copied. Param mean: 0.0000, std: 0.0140
2025-04-25 23:03:53,209 - INFO - Loading model.layers.6.mlp.gate_proj.weight:
2025-04-25 23:03:53,209 - INFO -   - Tensor shape: torch.Size([5632, 2048]), dtype: torch.bfloat16
2025-04-25 23:03:53,209 - INFO -   - Param shape: torch.Size([5632, 2048]), dtype: torch.float32
2025-04-25 23:03:53,388 - INFO -   - Copied. Param mean: 0.0000, std: 0.0196
2025-04-25 23:03:53,388 - INFO - Loading model.layers.6.mlp.up_proj.weight:
2025-04-25 23:03:53,388 - INFO -   - Tensor shape: torch.Size([5632, 2048]), dtype: torch.bfloat16
2025-04-25 23:03:53,389 - INFO -   - Param shape: torch.Size([5632, 2048]), dtype: torch.float32
2025-04-25 23:03:53,570 - INFO -   - Copied. Param mean: -0.0000, std: 0.0172
2025-04-25 23:03:53,570 - INFO - Loading model.layers.6.mlp.down_proj.weight:
2025-04-25 23:03:53,571 - INFO -   - Tensor shape: torch.Size([2048, 5632]), dtype: torch.bfloat16
2025-04-25 23:03:53,571 - INFO -   - Param shape: torch.Size([2048, 5632]), dtype: torch.float32
2025-04-25 23:03:53,765 - INFO -   - Copied. Param mean: -0.0000, std: 0.0171
2025-04-25 23:03:53,765 - INFO - Loading model.layers.7.input_layernorm.weight:
2025-04-25 23:03:53,765 - INFO -   - Tensor shape: torch.Size([2048]), dtype: torch.bfloat16
2025-04-25 23:03:53,766 - INFO -   - Param shape: torch.Size([2048]), dtype: torch.float32
2025-04-25 23:03:53,766 - INFO -   - Copied. Param mean: 0.3070, std: 0.0577
2025-04-25 23:03:53,766 - INFO - Loading model.layers.7.post_attention_layernorm.weight:
2025-04-25 23:03:53,766 - INFO -   - Tensor shape: torch.Size([2048]), dtype: torch.bfloat16
2025-04-25 23:03:53,767 - INFO -   - Param shape: torch.Size([2048]), dtype: torch.float32
2025-04-25 23:03:53,767 - INFO -   - Copied. Param mean: 0.2384, std: 0.0224
2025-04-25 23:03:53,767 - INFO - Loading model.layers.7.self_attn.q_proj.weight:
2025-04-25 23:03:53,767 - INFO -   - Tensor shape: torch.Size([2048, 2048]), dtype: torch.bfloat16
2025-04-25 23:03:53,768 - INFO -   - Param shape: torch.Size([2048, 2048]), dtype: torch.float32
2025-04-25 23:03:53,832 - INFO -   - Copied. Param mean: -0.0000, std: 0.0266
2025-04-25 23:03:53,832 - INFO - Loading model.layers.7.self_attn.k_proj.weight:
2025-04-25 23:03:53,833 - INFO -   - Tensor shape: torch.Size([256, 2048]), dtype: torch.bfloat16
2025-04-25 23:03:53,833 - INFO -   - Param shape: torch.Size([256, 2048]), dtype: torch.float32
2025-04-25 23:03:53,849 - INFO -   - Copied. Param mean: 0.0000, std: 0.0450
2025-04-25 23:03:53,849 - INFO - Loading model.layers.7.self_attn.v_proj.weight:
2025-04-25 23:03:53,849 - INFO -   - Tensor shape: torch.Size([256, 2048]), dtype: torch.bfloat16
2025-04-25 23:03:53,849 - INFO -   - Param shape: torch.Size([256, 2048]), dtype: torch.float32
2025-04-25 23:03:53,857 - INFO -   - Copied. Param mean: -0.0000, std: 0.0130
2025-04-25 23:03:53,858 - INFO - Loading model.layers.7.self_attn.o_proj.weight:
2025-04-25 23:03:53,858 - INFO -   - Tensor shape: torch.Size([2048, 2048]), dtype: torch.bfloat16
2025-04-25 23:03:53,858 - INFO -   - Param shape: torch.Size([2048, 2048]), dtype: torch.float32
2025-04-25 23:03:53,916 - INFO -   - Copied. Param mean: 0.0000, std: 0.0149
2025-04-25 23:03:53,917 - INFO - Loading model.layers.7.mlp.gate_proj.weight:
2025-04-25 23:03:53,917 - INFO -   - Tensor shape: torch.Size([5632, 2048]), dtype: torch.bfloat16
2025-04-25 23:03:53,917 - INFO -   - Param shape: torch.Size([5632, 2048]), dtype: torch.float32
2025-04-25 23:03:54,117 - INFO -   - Copied. Param mean: 0.0001, std: 0.0209
2025-04-25 23:03:54,117 - INFO - Loading model.layers.7.mlp.up_proj.weight:
2025-04-25 23:03:54,118 - INFO -   - Tensor shape: torch.Size([5632, 2048]), dtype: torch.bfloat16
2025-04-25 23:03:54,118 - INFO -   - Param shape: torch.Size([5632, 2048]), dtype: torch.float32
2025-04-25 23:03:54,314 - INFO -   - Copied. Param mean: 0.0000, std: 0.0168
2025-04-25 23:03:54,315 - INFO - Loading model.layers.7.mlp.down_proj.weight:
2025-04-25 23:03:54,315 - INFO -   - Tensor shape: torch.Size([2048, 5632]), dtype: torch.bfloat16
2025-04-25 23:03:54,316 - INFO -   - Param shape: torch.Size([2048, 5632]), dtype: torch.float32
2025-04-25 23:03:54,494 - INFO -   - Copied. Param mean: 0.0000, std: 0.0167
2025-04-25 23:03:54,495 - INFO - Loading model.layers.8.input_layernorm.weight:
2025-04-25 23:03:54,495 - INFO -   - Tensor shape: torch.Size([2048]), dtype: torch.bfloat16
2025-04-25 23:03:54,495 - INFO -   - Param shape: torch.Size([2048]), dtype: torch.float32
2025-04-25 23:03:54,495 - INFO -   - Copied. Param mean: 0.3188, std: 0.1083
2025-04-25 23:03:54,496 - INFO - Loading model.layers.8.post_attention_layernorm.weight:
2025-04-25 23:03:54,496 - INFO -   - Tensor shape: torch.Size([2048]), dtype: torch.bfloat16
2025-04-25 23:03:54,496 - INFO -   - Param shape: torch.Size([2048]), dtype: torch.float32
2025-04-25 23:03:54,496 - INFO -   - Copied. Param mean: 0.2645, std: 0.0304
2025-04-25 23:03:54,496 - INFO - Loading model.layers.8.self_attn.q_proj.weight:
2025-04-25 23:03:54,497 - INFO -   - Tensor shape: torch.Size([2048, 2048]), dtype: torch.bfloat16
2025-04-25 23:03:54,497 - INFO -   - Param shape: torch.Size([2048, 2048]), dtype: torch.float32
2025-04-25 23:03:54,561 - INFO -   - Copied. Param mean: -0.0000, std: 0.0273
2025-04-25 23:03:54,561 - INFO - Loading model.layers.8.self_attn.k_proj.weight:
2025-04-25 23:03:54,562 - INFO -   - Tensor shape: torch.Size([256, 2048]), dtype: torch.bfloat16
2025-04-25 23:03:54,562 - INFO -   - Param shape: torch.Size([256, 2048]), dtype: torch.float32
2025-04-25 23:03:54,577 - INFO -   - Copied. Param mean: -0.0000, std: 0.0466
2025-04-25 23:03:54,577 - INFO - Loading model.layers.8.self_attn.v_proj.weight:
2025-04-25 23:03:54,577 - INFO -   - Tensor shape: torch.Size([256, 2048]), dtype: torch.bfloat16
2025-04-25 23:03:54,578 - INFO -   - Param shape: torch.Size([256, 2048]), dtype: torch.float32
2025-04-25 23:03:54,592 - INFO -   - Copied. Param mean: -0.0000, std: 0.0121
2025-04-25 23:03:54,592 - INFO - Loading model.layers.8.self_attn.o_proj.weight:
2025-04-25 23:03:54,592 - INFO -   - Tensor shape: torch.Size([2048, 2048]), dtype: torch.bfloat16
2025-04-25 23:03:54,592 - INFO -   - Param shape: torch.Size([2048, 2048]), dtype: torch.float32
2025-04-25 23:03:54,647 - INFO -   - Copied. Param mean: -0.0000, std: 0.0145
2025-04-25 23:03:54,647 - INFO - Loading model.layers.8.mlp.gate_proj.weight:
2025-04-25 23:03:54,647 - INFO -   - Tensor shape: torch.Size([5632, 2048]), dtype: torch.bfloat16
2025-04-25 23:03:54,647 - INFO -   - Param shape: torch.Size([5632, 2048]), dtype: torch.float32
2025-04-25 23:03:54,809 - INFO -   - Copied. Param mean: 0.0001, std: 0.0202
2025-04-25 23:03:54,809 - INFO - Loading model.layers.8.mlp.up_proj.weight:
2025-04-25 23:03:54,810 - INFO -   - Tensor shape: torch.Size([5632, 2048]), dtype: torch.bfloat16
2025-04-25 23:03:54,810 - INFO -   - Param shape: torch.Size([5632, 2048]), dtype: torch.float32
2025-04-25 23:03:54,972 - INFO -   - Copied. Param mean: 0.0000, std: 0.0173
2025-04-25 23:03:54,972 - INFO - Loading model.layers.8.mlp.down_proj.weight:
2025-04-25 23:03:54,973 - INFO -   - Tensor shape: torch.Size([2048, 5632]), dtype: torch.bfloat16
2025-04-25 23:03:54,973 - INFO -   - Param shape: torch.Size([2048, 5632]), dtype: torch.float32
2025-04-25 23:03:55,135 - INFO -   - Copied. Param mean: 0.0000, std: 0.0172
2025-04-25 23:03:55,136 - INFO - Loading model.layers.9.input_layernorm.weight:
2025-04-25 23:03:55,136 - INFO -   - Tensor shape: torch.Size([2048]), dtype: torch.bfloat16
2025-04-25 23:03:55,136 - INFO -   - Param shape: torch.Size([2048]), dtype: torch.float32
2025-04-25 23:03:55,136 - INFO -   - Copied. Param mean: 0.3141, std: 0.0609
2025-04-25 23:03:55,137 - INFO - Loading model.layers.9.post_attention_layernorm.weight:
2025-04-25 23:03:55,137 - INFO -   - Tensor shape: torch.Size([2048]), dtype: torch.bfloat16
2025-04-25 23:03:55,137 - INFO -   - Param shape: torch.Size([2048]), dtype: torch.float32
2025-04-25 23:03:55,137 - INFO -   - Copied. Param mean: 0.2707, std: 0.0268
2025-04-25 23:03:55,137 - INFO - Loading model.layers.9.self_attn.q_proj.weight:
2025-04-25 23:03:55,137 - INFO -   - Tensor shape: torch.Size([2048, 2048]), dtype: torch.bfloat16
2025-04-25 23:03:55,137 - INFO -   - Param shape: torch.Size([2048, 2048]), dtype: torch.float32
2025-04-25 23:03:55,193 - INFO -   - Copied. Param mean: 0.0000, std: 0.0266
2025-04-25 23:03:55,193 - INFO - Loading model.layers.9.self_attn.k_proj.weight:
2025-04-25 23:03:55,193 - INFO -   - Tensor shape: torch.Size([256, 2048]), dtype: torch.bfloat16
2025-04-25 23:03:55,194 - INFO -   - Param shape: torch.Size([256, 2048]), dtype: torch.float32
2025-04-25 23:03:55,209 - INFO -   - Copied. Param mean: 0.0001, std: 0.0479
2025-04-25 23:03:55,209 - INFO - Loading model.layers.9.self_attn.v_proj.weight:
2025-04-25 23:03:55,209 - INFO -   - Tensor shape: torch.Size([256, 2048]), dtype: torch.bfloat16
2025-04-25 23:03:55,209 - INFO -   - Param shape: torch.Size([256, 2048]), dtype: torch.float32
2025-04-25 23:03:55,218 - INFO -   - Copied. Param mean: 0.0000, std: 0.0122
2025-04-25 23:03:55,218 - INFO - Loading model.layers.9.self_attn.o_proj.weight:
2025-04-25 23:03:55,218 - INFO -   - Tensor shape: torch.Size([2048, 2048]), dtype: torch.bfloat16
2025-04-25 23:03:55,218 - INFO -   - Param shape: torch.Size([2048, 2048]), dtype: torch.float32
2025-04-25 23:03:55,272 - INFO -   - Copied. Param mean: 0.0000, std: 0.0150
2025-04-25 23:03:55,273 - INFO - Loading model.layers.9.mlp.gate_proj.weight:
2025-04-25 23:03:55,273 - INFO -   - Tensor shape: torch.Size([5632, 2048]), dtype: torch.bfloat16
2025-04-25 23:03:55,273 - INFO -   - Param shape: torch.Size([5632, 2048]), dtype: torch.float32
2025-04-25 23:03:55,433 - INFO -   - Copied. Param mean: 0.0000, std: 0.0207
2025-04-25 23:03:55,433 - INFO - Loading model.layers.9.mlp.up_proj.weight:
2025-04-25 23:03:55,434 - INFO -   - Tensor shape: torch.Size([5632, 2048]), dtype: torch.bfloat16
2025-04-25 23:03:55,434 - INFO -   - Param shape: torch.Size([5632, 2048]), dtype: torch.float32
2025-04-25 23:03:55,593 - INFO -   - Copied. Param mean: 0.0000, std: 0.0171
2025-04-25 23:03:55,593 - INFO - Loading model.layers.9.mlp.down_proj.weight:
2025-04-25 23:03:55,594 - INFO -   - Tensor shape: torch.Size([2048, 5632]), dtype: torch.bfloat16
2025-04-25 23:03:55,594 - INFO -   - Param shape: torch.Size([2048, 5632]), dtype: torch.float32
2025-04-25 23:03:55,752 - INFO -   - Copied. Param mean: -0.0000, std: 0.0169
2025-04-25 23:03:55,752 - INFO - Loading model.layers.10.input_layernorm.weight:
2025-04-25 23:03:55,752 - INFO -   - Tensor shape: torch.Size([2048]), dtype: torch.bfloat16
2025-04-25 23:03:55,752 - INFO -   - Param shape: torch.Size([2048]), dtype: torch.float32
2025-04-25 23:03:55,753 - INFO -   - Copied. Param mean: 0.3328, std: 0.0563
2025-04-25 23:03:55,753 - INFO - Loading model.layers.10.post_attention_layernorm.weight:
2025-04-25 23:03:55,753 - INFO -   - Tensor shape: torch.Size([2048]), dtype: torch.bfloat16
2025-04-25 23:03:55,753 - INFO -   - Param shape: torch.Size([2048]), dtype: torch.float32
2025-04-25 23:03:55,753 - INFO -   - Copied. Param mean: 0.2796, std: 0.0302
2025-04-25 23:03:55,754 - INFO - Loading model.layers.10.self_attn.q_proj.weight:
2025-04-25 23:03:55,754 - INFO -   - Tensor shape: torch.Size([2048, 2048]), dtype: torch.bfloat16
2025-04-25 23:03:55,754 - INFO -   - Param shape: torch.Size([2048, 2048]), dtype: torch.float32
2025-04-25 23:03:55,812 - INFO -   - Copied. Param mean: 0.0000, std: 0.0268
2025-04-25 23:03:55,812 - INFO - Loading model.layers.10.self_attn.k_proj.weight:
2025-04-25 23:03:55,813 - INFO -   - Tensor shape: torch.Size([256, 2048]), dtype: torch.bfloat16
2025-04-25 23:03:55,813 - INFO -   - Param shape: torch.Size([256, 2048]), dtype: torch.float32
2025-04-25 23:03:55,820 - INFO -   - Copied. Param mean: -0.0000, std: 0.0493
2025-04-25 23:03:55,820 - INFO - Loading model.layers.10.self_attn.v_proj.weight:
2025-04-25 23:03:55,821 - INFO -   - Tensor shape: torch.Size([256, 2048]), dtype: torch.bfloat16
2025-04-25 23:03:55,821 - INFO -   - Param shape: torch.Size([256, 2048]), dtype: torch.float32
2025-04-25 23:03:55,836 - INFO -   - Copied. Param mean: -0.0000, std: 0.0123
2025-04-25 23:03:55,836 - INFO - Loading model.layers.10.self_attn.o_proj.weight:
2025-04-25 23:03:55,836 - INFO -   - Tensor shape: torch.Size([2048, 2048]), dtype: torch.bfloat16
2025-04-25 23:03:55,836 - INFO -   - Param shape: torch.Size([2048, 2048]), dtype: torch.float32
2025-04-25 23:03:55,892 - INFO -   - Copied. Param mean: 0.0000, std: 0.0149
2025-04-25 23:03:55,892 - INFO - Loading model.layers.10.mlp.gate_proj.weight:
2025-04-25 23:03:55,893 - INFO -   - Tensor shape: torch.Size([5632, 2048]), dtype: torch.bfloat16
2025-04-25 23:03:55,893 - INFO -   - Param shape: torch.Size([5632, 2048]), dtype: torch.float32
2025-04-25 23:03:56,048 - INFO -   - Copied. Param mean: 0.0000, std: 0.0204
2025-04-25 23:03:56,048 - INFO - Loading model.layers.10.mlp.up_proj.weight:
2025-04-25 23:03:56,049 - INFO -   - Tensor shape: torch.Size([5632, 2048]), dtype: torch.bfloat16
2025-04-25 23:03:56,049 - INFO -   - Param shape: torch.Size([5632, 2048]), dtype: torch.float32
2025-04-25 23:03:56,209 - INFO -   - Copied. Param mean: 0.0000, std: 0.0174
2025-04-25 23:03:56,210 - INFO - Loading model.layers.10.mlp.down_proj.weight:
2025-04-25 23:03:56,210 - INFO -   - Tensor shape: torch.Size([2048, 5632]), dtype: torch.bfloat16
2025-04-25 23:03:56,210 - INFO -   - Param shape: torch.Size([2048, 5632]), dtype: torch.float32
2025-04-25 23:03:56,363 - INFO -   - Copied. Param mean: 0.0000, std: 0.0173
2025-04-25 23:03:56,363 - INFO - Loading model.layers.11.input_layernorm.weight:
2025-04-25 23:03:56,364 - INFO -   - Tensor shape: torch.Size([2048]), dtype: torch.bfloat16
2025-04-25 23:03:56,364 - INFO -   - Param shape: torch.Size([2048]), dtype: torch.float32
2025-04-25 23:03:56,364 - INFO -   - Copied. Param mean: 0.3955, std: 0.0736
2025-04-25 23:03:56,364 - INFO - Loading model.layers.11.post_attention_layernorm.weight:
2025-04-25 23:03:56,365 - INFO -   - Tensor shape: torch.Size([2048]), dtype: torch.bfloat16
2025-04-25 23:03:56,365 - INFO -   - Param shape: torch.Size([2048]), dtype: torch.float32
2025-04-25 23:03:56,365 - INFO -   - Copied. Param mean: 0.2884, std: 0.0302
2025-04-25 23:03:56,365 - INFO - Loading model.layers.11.self_attn.q_proj.weight:
2025-04-25 23:03:56,365 - INFO -   - Tensor shape: torch.Size([2048, 2048]), dtype: torch.bfloat16
2025-04-25 23:03:56,365 - INFO -   - Param shape: torch.Size([2048, 2048]), dtype: torch.float32
2025-04-25 23:03:56,420 - INFO -   - Copied. Param mean: 0.0000, std: 0.0256
2025-04-25 23:03:56,420 - INFO - Loading model.layers.11.self_attn.k_proj.weight:
2025-04-25 23:03:56,420 - INFO -   - Tensor shape: torch.Size([256, 2048]), dtype: torch.bfloat16
2025-04-25 23:03:56,420 - INFO -   - Param shape: torch.Size([256, 2048]), dtype: torch.float32
2025-04-25 23:03:56,436 - INFO -   - Copied. Param mean: -0.0001, std: 0.0445
2025-04-25 23:03:56,436 - INFO - Loading model.layers.11.self_attn.v_proj.weight:
2025-04-25 23:03:56,437 - INFO -   - Tensor shape: torch.Size([256, 2048]), dtype: torch.bfloat16
2025-04-25 23:03:56,437 - INFO -   - Param shape: torch.Size([256, 2048]), dtype: torch.float32
2025-04-25 23:03:56,448 - INFO -   - Copied. Param mean: 0.0000, std: 0.0115
2025-04-25 23:03:56,449 - INFO - Loading model.layers.11.self_attn.o_proj.weight:
2025-04-25 23:03:56,449 - INFO -   - Tensor shape: torch.Size([2048, 2048]), dtype: torch.bfloat16
2025-04-25 23:03:56,449 - INFO -   - Param shape: torch.Size([2048, 2048]), dtype: torch.float32
2025-04-25 23:03:56,506 - INFO -   - Copied. Param mean: 0.0000, std: 0.0146
2025-04-25 23:03:56,506 - INFO - Loading model.layers.11.mlp.gate_proj.weight:
2025-04-25 23:03:56,507 - INFO -   - Tensor shape: torch.Size([5632, 2048]), dtype: torch.bfloat16
2025-04-25 23:03:56,507 - INFO -   - Param shape: torch.Size([5632, 2048]), dtype: torch.float32
2025-04-25 23:03:56,671 - INFO -   - Copied. Param mean: -0.0000, std: 0.0205
2025-04-25 23:03:56,671 - INFO - Loading model.layers.11.mlp.up_proj.weight:
2025-04-25 23:03:56,671 - INFO -   - Tensor shape: torch.Size([5632, 2048]), dtype: torch.bfloat16
2025-04-25 23:03:56,672 - INFO -   - Param shape: torch.Size([5632, 2048]), dtype: torch.float32
2025-04-25 23:03:56,826 - INFO -   - Copied. Param mean: -0.0000, std: 0.0174
2025-04-25 23:03:56,827 - INFO - Loading model.layers.11.mlp.down_proj.weight:
2025-04-25 23:03:56,827 - INFO -   - Tensor shape: torch.Size([2048, 5632]), dtype: torch.bfloat16
2025-04-25 23:03:56,827 - INFO -   - Param shape: torch.Size([2048, 5632]), dtype: torch.float32
2025-04-25 23:03:56,981 - INFO -   - Copied. Param mean: -0.0000, std: 0.0172
2025-04-25 23:03:56,982 - INFO - Loading model.layers.12.input_layernorm.weight:
2025-04-25 23:03:56,982 - INFO -   - Tensor shape: torch.Size([2048]), dtype: torch.bfloat16
2025-04-25 23:03:56,982 - INFO -   - Param shape: torch.Size([2048]), dtype: torch.float32
2025-04-25 23:03:56,983 - INFO -   - Copied. Param mean: 0.3438, std: 0.0674
2025-04-25 23:03:56,983 - INFO - Loading model.layers.12.post_attention_layernorm.weight:
2025-04-25 23:03:56,983 - INFO -   - Tensor shape: torch.Size([2048]), dtype: torch.bfloat16
2025-04-25 23:03:56,983 - INFO -   - Param shape: torch.Size([2048]), dtype: torch.float32
2025-04-25 23:03:56,984 - INFO -   - Copied. Param mean: 0.2991, std: 0.0256
2025-04-25 23:03:56,984 - INFO - Loading model.layers.12.self_attn.q_proj.weight:
2025-04-25 23:03:56,984 - INFO -   - Tensor shape: torch.Size([2048, 2048]), dtype: torch.bfloat16
2025-04-25 23:03:56,984 - INFO -   - Param shape: torch.Size([2048, 2048]), dtype: torch.float32
2025-04-25 23:03:57,043 - INFO -   - Copied. Param mean: -0.0000, std: 0.0259
2025-04-25 23:03:57,043 - INFO - Loading model.layers.12.self_attn.k_proj.weight:
2025-04-25 23:03:57,043 - INFO -   - Tensor shape: torch.Size([256, 2048]), dtype: torch.bfloat16
2025-04-25 23:03:57,043 - INFO -   - Param shape: torch.Size([256, 2048]), dtype: torch.float32
2025-04-25 23:03:57,055 - INFO -   - Copied. Param mean: -0.0001, std: 0.0462
2025-04-25 23:03:57,055 - INFO - Loading model.layers.12.self_attn.v_proj.weight:
2025-04-25 23:03:57,055 - INFO -   - Tensor shape: torch.Size([256, 2048]), dtype: torch.bfloat16
2025-04-25 23:03:57,056 - INFO -   - Param shape: torch.Size([256, 2048]), dtype: torch.float32
2025-04-25 23:03:57,066 - INFO -   - Copied. Param mean: -0.0001, std: 0.0144
2025-04-25 23:03:57,067 - INFO - Loading model.layers.12.self_attn.o_proj.weight:
2025-04-25 23:03:57,067 - INFO -   - Tensor shape: torch.Size([2048, 2048]), dtype: torch.bfloat16
2025-04-25 23:03:57,067 - INFO -   - Param shape: torch.Size([2048, 2048]), dtype: torch.float32
2025-04-25 23:03:57,122 - INFO -   - Copied. Param mean: -0.0000, std: 0.0157
2025-04-25 23:03:57,122 - INFO - Loading model.layers.12.mlp.gate_proj.weight:
2025-04-25 23:03:57,122 - INFO -   - Tensor shape: torch.Size([5632, 2048]), dtype: torch.bfloat16
2025-04-25 23:03:57,122 - INFO -   - Param shape: torch.Size([5632, 2048]), dtype: torch.float32
2025-04-25 23:03:57,286 - INFO -   - Copied. Param mean: -0.0000, std: 0.0212
2025-04-25 23:03:57,287 - INFO - Loading model.layers.12.mlp.up_proj.weight:
2025-04-25 23:03:57,287 - INFO -   - Tensor shape: torch.Size([5632, 2048]), dtype: torch.bfloat16
2025-04-25 23:03:57,287 - INFO -   - Param shape: torch.Size([5632, 2048]), dtype: torch.float32
2025-04-25 23:03:57,460 - INFO -   - Copied. Param mean: -0.0000, std: 0.0172
2025-04-25 23:03:57,460 - INFO - Loading model.layers.12.mlp.down_proj.weight:
2025-04-25 23:03:57,461 - INFO -   - Tensor shape: torch.Size([2048, 5632]), dtype: torch.bfloat16
2025-04-25 23:03:57,461 - INFO -   - Param shape: torch.Size([2048, 5632]), dtype: torch.float32
2025-04-25 23:03:57,628 - INFO -   - Copied. Param mean: -0.0000, std: 0.0170
2025-04-25 23:03:57,628 - INFO - Loading model.layers.13.input_layernorm.weight:
2025-04-25 23:03:57,628 - INFO -   - Tensor shape: torch.Size([2048]), dtype: torch.bfloat16
2025-04-25 23:03:57,629 - INFO -   - Param shape: torch.Size([2048]), dtype: torch.float32
2025-04-25 23:03:57,629 - INFO -   - Copied. Param mean: 0.3773, std: 0.0761
2025-04-25 23:03:57,629 - INFO - Loading model.layers.13.post_attention_layernorm.weight:
2025-04-25 23:03:57,629 - INFO -   - Tensor shape: torch.Size([2048]), dtype: torch.bfloat16
2025-04-25 23:03:57,630 - INFO -   - Param shape: torch.Size([2048]), dtype: torch.float32
2025-04-25 23:03:57,630 - INFO -   - Copied. Param mean: 0.3128, std: 0.0242
2025-04-25 23:03:57,630 - INFO - Loading model.layers.13.self_attn.q_proj.weight:
2025-04-25 23:03:57,631 - INFO -   - Tensor shape: torch.Size([2048, 2048]), dtype: torch.bfloat16
2025-04-25 23:03:57,631 - INFO -   - Param shape: torch.Size([2048, 2048]), dtype: torch.float32
2025-04-25 23:03:57,690 - INFO -   - Copied. Param mean: 0.0000, std: 0.0254
2025-04-25 23:03:57,690 - INFO - Loading model.layers.13.self_attn.k_proj.weight:
2025-04-25 23:03:57,691 - INFO -   - Tensor shape: torch.Size([256, 2048]), dtype: torch.bfloat16
2025-04-25 23:03:57,691 - INFO -   - Param shape: torch.Size([256, 2048]), dtype: torch.float32
2025-04-25 23:03:57,707 - INFO -   - Copied. Param mean: -0.0000, std: 0.0469
2025-04-25 23:03:57,707 - INFO - Loading model.layers.13.self_attn.v_proj.weight:
2025-04-25 23:03:57,708 - INFO -   - Tensor shape: torch.Size([256, 2048]), dtype: torch.bfloat16
2025-04-25 23:03:57,708 - INFO -   - Param shape: torch.Size([256, 2048]), dtype: torch.float32
2025-04-25 23:03:57,725 - INFO -   - Copied. Param mean: -0.0000, std: 0.0123
2025-04-25 23:03:57,726 - INFO - Loading model.layers.13.self_attn.o_proj.weight:
2025-04-25 23:03:57,726 - INFO -   - Tensor shape: torch.Size([2048, 2048]), dtype: torch.bfloat16
2025-04-25 23:03:57,726 - INFO -   - Param shape: torch.Size([2048, 2048]), dtype: torch.float32
2025-04-25 23:03:57,784 - INFO -   - Copied. Param mean: -0.0000, std: 0.0151
2025-04-25 23:03:57,784 - INFO - Loading model.layers.13.mlp.gate_proj.weight:
2025-04-25 23:03:57,785 - INFO -   - Tensor shape: torch.Size([5632, 2048]), dtype: torch.bfloat16
2025-04-25 23:03:57,785 - INFO -   - Param shape: torch.Size([5632, 2048]), dtype: torch.float32
2025-04-25 23:03:57,951 - INFO -   - Copied. Param mean: -0.0000, std: 0.0211
2025-04-25 23:03:57,952 - INFO - Loading model.layers.13.mlp.up_proj.weight:
2025-04-25 23:03:57,952 - INFO -   - Tensor shape: torch.Size([5632, 2048]), dtype: torch.bfloat16
2025-04-25 23:03:57,952 - INFO -   - Param shape: torch.Size([5632, 2048]), dtype: torch.float32
2025-04-25 23:03:58,117 - INFO -   - Copied. Param mean: -0.0000, std: 0.0174
2025-04-25 23:03:58,117 - INFO - Loading model.layers.13.mlp.down_proj.weight:
2025-04-25 23:03:58,118 - INFO -   - Tensor shape: torch.Size([2048, 5632]), dtype: torch.bfloat16
2025-04-25 23:03:58,118 - INFO -   - Param shape: torch.Size([2048, 5632]), dtype: torch.float32
2025-04-25 23:03:58,280 - INFO -   - Copied. Param mean: 0.0000, std: 0.0172
2025-04-25 23:03:58,280 - INFO - Loading model.layers.14.input_layernorm.weight:
2025-04-25 23:03:58,281 - INFO -   - Tensor shape: torch.Size([2048]), dtype: torch.bfloat16
2025-04-25 23:03:58,281 - INFO -   - Param shape: torch.Size([2048]), dtype: torch.float32
2025-04-25 23:03:58,281 - INFO -   - Copied. Param mean: 0.3614, std: 0.0651
2025-04-25 23:03:58,281 - INFO - Loading model.layers.14.post_attention_layernorm.weight:
2025-04-25 23:03:58,281 - INFO -   - Tensor shape: torch.Size([2048]), dtype: torch.bfloat16
2025-04-25 23:03:58,282 - INFO -   - Param shape: torch.Size([2048]), dtype: torch.float32
2025-04-25 23:03:58,282 - INFO -   - Copied. Param mean: 0.3289, std: 0.0258
2025-04-25 23:03:58,282 - INFO - Loading model.layers.14.self_attn.q_proj.weight:
2025-04-25 23:03:58,282 - INFO -   - Tensor shape: torch.Size([2048, 2048]), dtype: torch.bfloat16
2025-04-25 23:03:58,282 - INFO -   - Param shape: torch.Size([2048, 2048]), dtype: torch.float32
2025-04-25 23:03:58,337 - INFO -   - Copied. Param mean: -0.0000, std: 0.0256
2025-04-25 23:03:58,337 - INFO - Loading model.layers.14.self_attn.k_proj.weight:
2025-04-25 23:03:58,337 - INFO -   - Tensor shape: torch.Size([256, 2048]), dtype: torch.bfloat16
2025-04-25 23:03:58,337 - INFO -   - Param shape: torch.Size([256, 2048]), dtype: torch.float32
2025-04-25 23:03:58,351 - INFO -   - Copied. Param mean: -0.0000, std: 0.0482
2025-04-25 23:03:58,352 - INFO - Loading model.layers.14.self_attn.v_proj.weight:
2025-04-25 23:03:58,352 - INFO -   - Tensor shape: torch.Size([256, 2048]), dtype: torch.bfloat16
2025-04-25 23:03:58,352 - INFO -   - Param shape: torch.Size([256, 2048]), dtype: torch.float32
2025-04-25 23:03:58,364 - INFO -   - Copied. Param mean: 0.0000, std: 0.0134
2025-04-25 23:03:58,364 - INFO - Loading model.layers.14.self_attn.o_proj.weight:
2025-04-25 23:03:58,364 - INFO -   - Tensor shape: torch.Size([2048, 2048]), dtype: torch.bfloat16
2025-04-25 23:03:58,364 - INFO -   - Param shape: torch.Size([2048, 2048]), dtype: torch.float32
2025-04-25 23:03:58,422 - INFO -   - Copied. Param mean: -0.0000, std: 0.0155
2025-04-25 23:03:58,422 - INFO - Loading model.layers.14.mlp.gate_proj.weight:
2025-04-25 23:03:58,422 - INFO -   - Tensor shape: torch.Size([5632, 2048]), dtype: torch.bfloat16
2025-04-25 23:03:58,422 - INFO -   - Param shape: torch.Size([5632, 2048]), dtype: torch.float32
2025-04-25 23:03:58,582 - INFO -   - Copied. Param mean: -0.0001, std: 0.0211
2025-04-25 23:03:58,582 - INFO - Loading model.layers.14.mlp.up_proj.weight:
2025-04-25 23:03:58,583 - INFO -   - Tensor shape: torch.Size([5632, 2048]), dtype: torch.bfloat16
2025-04-25 23:03:58,583 - INFO -   - Param shape: torch.Size([5632, 2048]), dtype: torch.float32
2025-04-25 23:03:58,746 - INFO -   - Copied. Param mean: 0.0000, std: 0.0179
2025-04-25 23:03:58,747 - INFO - Loading model.layers.14.mlp.down_proj.weight:
2025-04-25 23:03:58,747 - INFO -   - Tensor shape: torch.Size([2048, 5632]), dtype: torch.bfloat16
2025-04-25 23:03:58,747 - INFO -   - Param shape: torch.Size([2048, 5632]), dtype: torch.float32
2025-04-25 23:03:58,903 - INFO -   - Copied. Param mean: 0.0000, std: 0.0176
2025-04-25 23:03:58,904 - INFO - Loading model.layers.15.input_layernorm.weight:
2025-04-25 23:03:58,904 - INFO -   - Tensor shape: torch.Size([2048]), dtype: torch.bfloat16
2025-04-25 23:03:58,904 - INFO -   - Param shape: torch.Size([2048]), dtype: torch.float32
2025-04-25 23:03:58,904 - INFO -   - Copied. Param mean: 0.4188, std: 0.0651
2025-04-25 23:03:58,905 - INFO - Loading model.layers.15.post_attention_layernorm.weight:
2025-04-25 23:03:58,905 - INFO -   - Tensor shape: torch.Size([2048]), dtype: torch.bfloat16
2025-04-25 23:03:58,905 - INFO -   - Param shape: torch.Size([2048]), dtype: torch.float32
2025-04-25 23:03:58,905 - INFO -   - Copied. Param mean: 0.3524, std: 0.0248
2025-04-25 23:03:58,905 - INFO - Loading model.layers.15.self_attn.q_proj.weight:
2025-04-25 23:03:58,906 - INFO -   - Tensor shape: torch.Size([2048, 2048]), dtype: torch.bfloat16
2025-04-25 23:03:58,906 - INFO -   - Param shape: torch.Size([2048, 2048]), dtype: torch.float32
2025-04-25 23:03:58,961 - INFO -   - Copied. Param mean: -0.0000, std: 0.0260
2025-04-25 23:03:58,961 - INFO - Loading model.layers.15.self_attn.k_proj.weight:
2025-04-25 23:03:58,962 - INFO -   - Tensor shape: torch.Size([256, 2048]), dtype: torch.bfloat16
2025-04-25 23:03:58,962 - INFO -   - Param shape: torch.Size([256, 2048]), dtype: torch.float32
2025-04-25 23:03:58,978 - INFO -   - Copied. Param mean: 0.0001, std: 0.0428
2025-04-25 23:03:58,978 - INFO - Loading model.layers.15.self_attn.v_proj.weight:
2025-04-25 23:03:58,978 - INFO -   - Tensor shape: torch.Size([256, 2048]), dtype: torch.bfloat16
2025-04-25 23:03:58,978 - INFO -   - Param shape: torch.Size([256, 2048]), dtype: torch.float32
2025-04-25 23:03:58,989 - INFO -   - Copied. Param mean: -0.0000, std: 0.0137
2025-04-25 23:03:58,989 - INFO - Loading model.layers.15.self_attn.o_proj.weight:
2025-04-25 23:03:58,989 - INFO -   - Tensor shape: torch.Size([2048, 2048]), dtype: torch.bfloat16
2025-04-25 23:03:58,989 - INFO -   - Param shape: torch.Size([2048, 2048]), dtype: torch.float32
2025-04-25 23:03:59,044 - INFO -   - Copied. Param mean: 0.0000, std: 0.0159
2025-04-25 23:03:59,045 - INFO - Loading model.layers.15.mlp.gate_proj.weight:
2025-04-25 23:03:59,045 - INFO -   - Tensor shape: torch.Size([5632, 2048]), dtype: torch.bfloat16
2025-04-25 23:03:59,045 - INFO -   - Param shape: torch.Size([5632, 2048]), dtype: torch.float32
2025-04-25 23:03:59,198 - INFO -   - Copied. Param mean: -0.0001, std: 0.0211
2025-04-25 23:03:59,199 - INFO - Loading model.layers.15.mlp.up_proj.weight:
2025-04-25 23:03:59,199 - INFO -   - Tensor shape: torch.Size([5632, 2048]), dtype: torch.bfloat16
2025-04-25 23:03:59,199 - INFO -   - Param shape: torch.Size([5632, 2048]), dtype: torch.float32
2025-04-25 23:03:59,353 - INFO -   - Copied. Param mean: -0.0000, std: 0.0180
2025-04-25 23:03:59,353 - INFO - Loading model.layers.15.mlp.down_proj.weight:
2025-04-25 23:03:59,354 - INFO -   - Tensor shape: torch.Size([2048, 5632]), dtype: torch.bfloat16
2025-04-25 23:03:59,354 - INFO -   - Param shape: torch.Size([2048, 5632]), dtype: torch.float32
2025-04-25 23:03:59,517 - INFO -   - Copied. Param mean: 0.0000, std: 0.0177
2025-04-25 23:03:59,517 - INFO - Loading model.layers.16.input_layernorm.weight:
2025-04-25 23:03:59,518 - INFO -   - Tensor shape: torch.Size([2048]), dtype: torch.bfloat16
2025-04-25 23:03:59,518 - INFO -   - Param shape: torch.Size([2048]), dtype: torch.float32
2025-04-25 23:03:59,518 - INFO -   - Copied. Param mean: 0.4019, std: 0.0667
2025-04-25 23:03:59,518 - INFO - Loading model.layers.16.post_attention_layernorm.weight:
2025-04-25 23:03:59,518 - INFO -   - Tensor shape: torch.Size([2048]), dtype: torch.bfloat16
2025-04-25 23:03:59,519 - INFO -   - Param shape: torch.Size([2048]), dtype: torch.float32
2025-04-25 23:03:59,519 - INFO -   - Copied. Param mean: 0.3908, std: 0.0267
2025-04-25 23:03:59,519 - INFO - Loading model.layers.16.self_attn.q_proj.weight:
2025-04-25 23:03:59,519 - INFO -   - Tensor shape: torch.Size([2048, 2048]), dtype: torch.bfloat16
2025-04-25 23:03:59,519 - INFO -   - Param shape: torch.Size([2048, 2048]), dtype: torch.float32
2025-04-25 23:03:59,575 - INFO -   - Copied. Param mean: -0.0000, std: 0.0265
2025-04-25 23:03:59,575 - INFO - Loading model.layers.16.self_attn.k_proj.weight:
2025-04-25 23:03:59,575 - INFO -   - Tensor shape: torch.Size([256, 2048]), dtype: torch.bfloat16
2025-04-25 23:03:59,575 - INFO -   - Param shape: torch.Size([256, 2048]), dtype: torch.float32
2025-04-25 23:03:59,588 - INFO -   - Copied. Param mean: 0.0000, std: 0.0440
2025-04-25 23:03:59,588 - INFO - Loading model.layers.16.self_attn.v_proj.weight:
2025-04-25 23:03:59,588 - INFO -   - Tensor shape: torch.Size([256, 2048]), dtype: torch.bfloat16
2025-04-25 23:03:59,589 - INFO -   - Param shape: torch.Size([256, 2048]), dtype: torch.float32
2025-04-25 23:03:59,600 - INFO -   - Copied. Param mean: -0.0000, std: 0.0151
2025-04-25 23:03:59,600 - INFO - Loading model.layers.16.self_attn.o_proj.weight:
2025-04-25 23:03:59,601 - INFO -   - Tensor shape: torch.Size([2048, 2048]), dtype: torch.bfloat16
2025-04-25 23:03:59,601 - INFO -   - Param shape: torch.Size([2048, 2048]), dtype: torch.float32
2025-04-25 23:03:59,657 - INFO -   - Copied. Param mean: -0.0000, std: 0.0158
2025-04-25 23:03:59,658 - INFO - Loading model.layers.16.mlp.gate_proj.weight:
2025-04-25 23:03:59,658 - INFO -   - Tensor shape: torch.Size([5632, 2048]), dtype: torch.bfloat16
2025-04-25 23:03:59,658 - INFO -   - Param shape: torch.Size([5632, 2048]), dtype: torch.float32
2025-04-25 23:03:59,829 - INFO -   - Copied. Param mean: -0.0001, std: 0.0216
2025-04-25 23:03:59,830 - INFO - Loading model.layers.16.mlp.up_proj.weight:
2025-04-25 23:03:59,830 - INFO -   - Tensor shape: torch.Size([5632, 2048]), dtype: torch.bfloat16
2025-04-25 23:03:59,830 - INFO -   - Param shape: torch.Size([5632, 2048]), dtype: torch.float32
2025-04-25 23:03:59,999 - INFO -   - Copied. Param mean: 0.0000, std: 0.0180
2025-04-25 23:04:00,000 - INFO - Loading model.layers.16.mlp.down_proj.weight:
2025-04-25 23:04:00,000 - INFO -   - Tensor shape: torch.Size([2048, 5632]), dtype: torch.bfloat16
2025-04-25 23:04:00,000 - INFO -   - Param shape: torch.Size([2048, 5632]), dtype: torch.float32
2025-04-25 23:04:00,180 - INFO -   - Copied. Param mean: -0.0000, std: 0.0176
2025-04-25 23:04:00,181 - INFO - Loading model.layers.17.input_layernorm.weight:
2025-04-25 23:04:00,181 - INFO -   - Tensor shape: torch.Size([2048]), dtype: torch.bfloat16
2025-04-25 23:04:00,181 - INFO -   - Param shape: torch.Size([2048]), dtype: torch.float32
2025-04-25 23:04:00,181 - INFO -   - Copied. Param mean: 0.4315, std: 0.0760
2025-04-25 23:04:00,182 - INFO - Loading model.layers.17.post_attention_layernorm.weight:
2025-04-25 23:04:00,182 - INFO -   - Tensor shape: torch.Size([2048]), dtype: torch.bfloat16
2025-04-25 23:04:00,182 - INFO -   - Param shape: torch.Size([2048]), dtype: torch.float32
2025-04-25 23:04:00,182 - INFO -   - Copied. Param mean: 0.4231, std: 0.0308
2025-04-25 23:04:00,182 - INFO - Loading model.layers.17.self_attn.q_proj.weight:
2025-04-25 23:04:00,182 - INFO -   - Tensor shape: torch.Size([2048, 2048]), dtype: torch.bfloat16
2025-04-25 23:04:00,183 - INFO -   - Param shape: torch.Size([2048, 2048]), dtype: torch.float32
2025-04-25 23:04:00,241 - INFO -   - Copied. Param mean: 0.0000, std: 0.0243
2025-04-25 23:04:00,241 - INFO - Loading model.layers.17.self_attn.k_proj.weight:
2025-04-25 23:04:00,242 - INFO -   - Tensor shape: torch.Size([256, 2048]), dtype: torch.bfloat16
2025-04-25 23:04:00,242 - INFO -   - Param shape: torch.Size([256, 2048]), dtype: torch.float32
2025-04-25 23:04:00,260 - INFO -   - Copied. Param mean: 0.0000, std: 0.0404
2025-04-25 23:04:00,260 - INFO - Loading model.layers.17.self_attn.v_proj.weight:
2025-04-25 23:04:00,261 - INFO -   - Tensor shape: torch.Size([256, 2048]), dtype: torch.bfloat16
2025-04-25 23:04:00,261 - INFO -   - Param shape: torch.Size([256, 2048]), dtype: torch.float32
2025-04-25 23:04:00,273 - INFO -   - Copied. Param mean: -0.0000, std: 0.0188
2025-04-25 23:04:00,273 - INFO - Loading model.layers.17.self_attn.o_proj.weight:
2025-04-25 23:04:00,273 - INFO -   - Tensor shape: torch.Size([2048, 2048]), dtype: torch.bfloat16
2025-04-25 23:04:00,274 - INFO -   - Param shape: torch.Size([2048, 2048]), dtype: torch.float32
2025-04-25 23:04:00,342 - INFO -   - Copied. Param mean: -0.0000, std: 0.0171
2025-04-25 23:04:00,342 - INFO - Loading model.layers.17.mlp.gate_proj.weight:
2025-04-25 23:04:00,342 - INFO -   - Tensor shape: torch.Size([5632, 2048]), dtype: torch.bfloat16
2025-04-25 23:04:00,342 - INFO -   - Param shape: torch.Size([5632, 2048]), dtype: torch.float32
2025-04-25 23:04:00,535 - INFO -   - Copied. Param mean: -0.0001, std: 0.0217
2025-04-25 23:04:00,536 - INFO - Loading model.layers.17.mlp.up_proj.weight:
2025-04-25 23:04:00,536 - INFO -   - Tensor shape: torch.Size([5632, 2048]), dtype: torch.bfloat16
2025-04-25 23:04:00,536 - INFO -   - Param shape: torch.Size([5632, 2048]), dtype: torch.float32
2025-04-25 23:04:00,758 - INFO -   - Copied. Param mean: -0.0000, std: 0.0183
2025-04-25 23:04:00,759 - INFO - Loading model.layers.17.mlp.down_proj.weight:
2025-04-25 23:04:00,759 - INFO -   - Tensor shape: torch.Size([2048, 5632]), dtype: torch.bfloat16
2025-04-25 23:04:00,759 - INFO -   - Param shape: torch.Size([2048, 5632]), dtype: torch.float32
2025-04-25 23:04:00,937 - INFO -   - Copied. Param mean: -0.0000, std: 0.0180
2025-04-25 23:04:00,937 - INFO - Loading model.layers.18.input_layernorm.weight:
2025-04-25 23:04:00,938 - INFO -   - Tensor shape: torch.Size([2048]), dtype: torch.bfloat16
2025-04-25 23:04:00,938 - INFO -   - Param shape: torch.Size([2048]), dtype: torch.float32
2025-04-25 23:04:00,938 - INFO -   - Copied. Param mean: 0.4387, std: 0.0815
2025-04-25 23:04:00,938 - INFO - Loading model.layers.18.post_attention_layernorm.weight:
2025-04-25 23:04:00,939 - INFO -   - Tensor shape: torch.Size([2048]), dtype: torch.bfloat16
2025-04-25 23:04:00,939 - INFO -   - Param shape: torch.Size([2048]), dtype: torch.float32
2025-04-25 23:04:00,939 - INFO -   - Copied. Param mean: 0.4623, std: 0.0351
2025-04-25 23:04:00,940 - INFO - Loading model.layers.18.self_attn.q_proj.weight:
2025-04-25 23:04:00,940 - INFO -   - Tensor shape: torch.Size([2048, 2048]), dtype: torch.bfloat16
2025-04-25 23:04:00,940 - INFO -   - Param shape: torch.Size([2048, 2048]), dtype: torch.float32
2025-04-25 23:04:00,997 - INFO -   - Copied. Param mean: 0.0000, std: 0.0251
2025-04-25 23:04:00,998 - INFO - Loading model.layers.18.self_attn.k_proj.weight:
2025-04-25 23:04:00,998 - INFO -   - Tensor shape: torch.Size([256, 2048]), dtype: torch.bfloat16
2025-04-25 23:04:00,998 - INFO -   - Param shape: torch.Size([256, 2048]), dtype: torch.float32
2025-04-25 23:04:01,013 - INFO -   - Copied. Param mean: -0.0000, std: 0.0403
2025-04-25 23:04:01,013 - INFO - Loading model.layers.18.self_attn.v_proj.weight:
2025-04-25 23:04:01,013 - INFO -   - Tensor shape: torch.Size([256, 2048]), dtype: torch.bfloat16
2025-04-25 23:04:01,013 - INFO -   - Param shape: torch.Size([256, 2048]), dtype: torch.float32
2025-04-25 23:04:01,027 - INFO -   - Copied. Param mean: -0.0000, std: 0.0196
2025-04-25 23:04:01,027 - INFO - Loading model.layers.18.self_attn.o_proj.weight:
2025-04-25 23:04:01,027 - INFO -   - Tensor shape: torch.Size([2048, 2048]), dtype: torch.bfloat16
2025-04-25 23:04:01,027 - INFO -   - Param shape: torch.Size([2048, 2048]), dtype: torch.float32
2025-04-25 23:04:01,096 - INFO -   - Copied. Param mean: 0.0000, std: 0.0175
2025-04-25 23:04:01,096 - INFO - Loading model.layers.18.mlp.gate_proj.weight:
2025-04-25 23:04:01,097 - INFO -   - Tensor shape: torch.Size([5632, 2048]), dtype: torch.bfloat16
2025-04-25 23:04:01,097 - INFO -   - Param shape: torch.Size([5632, 2048]), dtype: torch.float32
2025-04-25 23:04:01,282 - INFO -   - Copied. Param mean: -0.0001, std: 0.0218
2025-04-25 23:04:01,282 - INFO - Loading model.layers.18.mlp.up_proj.weight:
2025-04-25 23:04:01,283 - INFO -   - Tensor shape: torch.Size([5632, 2048]), dtype: torch.bfloat16
2025-04-25 23:04:01,283 - INFO -   - Param shape: torch.Size([5632, 2048]), dtype: torch.float32
2025-04-25 23:04:01,471 - INFO -   - Copied. Param mean: 0.0000, std: 0.0186
2025-04-25 23:04:01,472 - INFO - Loading model.layers.18.mlp.down_proj.weight:
2025-04-25 23:04:01,472 - INFO -   - Tensor shape: torch.Size([2048, 5632]), dtype: torch.bfloat16
2025-04-25 23:04:01,472 - INFO -   - Param shape: torch.Size([2048, 5632]), dtype: torch.float32
2025-04-25 23:04:01,644 - INFO -   - Copied. Param mean: -0.0000, std: 0.0182
2025-04-25 23:04:01,644 - INFO - Loading model.layers.19.input_layernorm.weight:
2025-04-25 23:04:01,645 - INFO -   - Tensor shape: torch.Size([2048]), dtype: torch.bfloat16
2025-04-25 23:04:01,645 - INFO -   - Param shape: torch.Size([2048]), dtype: torch.float32
2025-04-25 23:04:01,645 - INFO -   - Copied. Param mean: 0.4350, std: 0.0937
2025-04-25 23:04:01,646 - INFO - Loading model.layers.19.post_attention_layernorm.weight:
2025-04-25 23:04:01,646 - INFO -   - Tensor shape: torch.Size([2048]), dtype: torch.bfloat16
2025-04-25 23:04:01,646 - INFO -   - Param shape: torch.Size([2048]), dtype: torch.float32
2025-04-25 23:04:01,646 - INFO -   - Copied. Param mean: 0.4969, std: 0.0362
2025-04-25 23:04:01,646 - INFO - Loading model.layers.19.self_attn.q_proj.weight:
2025-04-25 23:04:01,647 - INFO -   - Tensor shape: torch.Size([2048, 2048]), dtype: torch.bfloat16
2025-04-25 23:04:01,647 - INFO -   - Param shape: torch.Size([2048, 2048]), dtype: torch.float32
2025-04-25 23:04:01,710 - INFO -   - Copied. Param mean: -0.0000, std: 0.0242
2025-04-25 23:04:01,710 - INFO - Loading model.layers.19.self_attn.k_proj.weight:
2025-04-25 23:04:01,710 - INFO -   - Tensor shape: torch.Size([256, 2048]), dtype: torch.bfloat16
2025-04-25 23:04:01,710 - INFO -   - Param shape: torch.Size([256, 2048]), dtype: torch.float32
2025-04-25 23:04:01,729 - INFO -   - Copied. Param mean: 0.0000, std: 0.0386
2025-04-25 23:04:01,730 - INFO - Loading model.layers.19.self_attn.v_proj.weight:
2025-04-25 23:04:01,730 - INFO -   - Tensor shape: torch.Size([256, 2048]), dtype: torch.bfloat16
2025-04-25 23:04:01,730 - INFO -   - Param shape: torch.Size([256, 2048]), dtype: torch.float32
2025-04-25 23:04:01,744 - INFO -   - Copied. Param mean: 0.0000, std: 0.0231
2025-04-25 23:04:01,744 - INFO - Loading model.layers.19.self_attn.o_proj.weight:
2025-04-25 23:04:01,744 - INFO -   - Tensor shape: torch.Size([2048, 2048]), dtype: torch.bfloat16
2025-04-25 23:04:01,744 - INFO -   - Param shape: torch.Size([2048, 2048]), dtype: torch.float32
2025-04-25 23:04:01,813 - INFO -   - Copied. Param mean: -0.0000, std: 0.0184
2025-04-25 23:04:01,823 - INFO - Loading model.layers.19.mlp.gate_proj.weight:
2025-04-25 23:04:01,824 - INFO -   - Tensor shape: torch.Size([5632, 2048]), dtype: torch.bfloat16
2025-04-25 23:04:01,824 - INFO -   - Param shape: torch.Size([5632, 2048]), dtype: torch.float32
2025-04-25 23:04:02,006 - INFO -   - Copied. Param mean: -0.0001, std: 0.0218
2025-04-25 23:04:02,006 - INFO - Loading model.layers.19.mlp.up_proj.weight:
2025-04-25 23:04:02,007 - INFO -   - Tensor shape: torch.Size([5632, 2048]), dtype: torch.bfloat16
2025-04-25 23:04:02,007 - INFO -   - Param shape: torch.Size([5632, 2048]), dtype: torch.float32
2025-04-25 23:04:02,201 - INFO -   - Copied. Param mean: -0.0000, std: 0.0190
2025-04-25 23:04:02,201 - INFO - Loading model.layers.19.mlp.down_proj.weight:
2025-04-25 23:04:02,201 - INFO -   - Tensor shape: torch.Size([2048, 5632]), dtype: torch.bfloat16
2025-04-25 23:04:02,201 - INFO -   - Param shape: torch.Size([2048, 5632]), dtype: torch.float32
2025-04-25 23:04:02,401 - INFO -   - Copied. Param mean: -0.0000, std: 0.0186
2025-04-25 23:04:02,402 - INFO - Loading model.layers.20.input_layernorm.weight:
2025-04-25 23:04:02,402 - INFO -   - Tensor shape: torch.Size([2048]), dtype: torch.bfloat16
2025-04-25 23:04:02,402 - INFO -   - Param shape: torch.Size([2048]), dtype: torch.float32
2025-04-25 23:04:02,403 - INFO -   - Copied. Param mean: 0.4330, std: 0.0860
2025-04-25 23:04:02,403 - INFO - Loading model.layers.20.post_attention_layernorm.weight:
2025-04-25 23:04:02,403 - INFO -   - Tensor shape: torch.Size([2048]), dtype: torch.bfloat16
2025-04-25 23:04:02,403 - INFO -   - Param shape: torch.Size([2048]), dtype: torch.float32
2025-04-25 23:04:02,404 - INFO -   - Copied. Param mean: 0.5282, std: 0.0366
2025-04-25 23:04:02,404 - INFO - Loading model.layers.20.self_attn.q_proj.weight:
2025-04-25 23:04:02,404 - INFO -   - Tensor shape: torch.Size([2048, 2048]), dtype: torch.bfloat16
2025-04-25 23:04:02,404 - INFO -   - Param shape: torch.Size([2048, 2048]), dtype: torch.float32
2025-04-25 23:04:02,466 - INFO -   - Copied. Param mean: 0.0000, std: 0.0247
2025-04-25 23:04:02,466 - INFO - Loading model.layers.20.self_attn.k_proj.weight:
2025-04-25 23:04:02,466 - INFO -   - Tensor shape: torch.Size([256, 2048]), dtype: torch.bfloat16
2025-04-25 23:04:02,467 - INFO -   - Param shape: torch.Size([256, 2048]), dtype: torch.float32
2025-04-25 23:04:02,475 - INFO -   - Copied. Param mean: 0.0001, std: 0.0398
2025-04-25 23:04:02,475 - INFO - Loading model.layers.20.self_attn.v_proj.weight:
2025-04-25 23:04:02,475 - INFO -   - Tensor shape: torch.Size([256, 2048]), dtype: torch.bfloat16
2025-04-25 23:04:02,476 - INFO -   - Param shape: torch.Size([256, 2048]), dtype: torch.float32
2025-04-25 23:04:02,486 - INFO -   - Copied. Param mean: 0.0000, std: 0.0235
2025-04-25 23:04:02,487 - INFO - Loading model.layers.20.self_attn.o_proj.weight:
2025-04-25 23:04:02,487 - INFO -   - Tensor shape: torch.Size([2048, 2048]), dtype: torch.bfloat16
2025-04-25 23:04:02,487 - INFO -   - Param shape: torch.Size([2048, 2048]), dtype: torch.float32
2025-04-25 23:04:02,545 - INFO -   - Copied. Param mean: 0.0000, std: 0.0184
2025-04-25 23:04:02,545 - INFO - Loading model.layers.20.mlp.gate_proj.weight:
2025-04-25 23:04:02,545 - INFO -   - Tensor shape: torch.Size([5632, 2048]), dtype: torch.bfloat16
2025-04-25 23:04:02,546 - INFO -   - Param shape: torch.Size([5632, 2048]), dtype: torch.float32
2025-04-25 23:04:02,710 - INFO -   - Copied. Param mean: -0.0000, std: 0.0219
2025-04-25 23:04:02,710 - INFO - Loading model.layers.20.mlp.up_proj.weight:
2025-04-25 23:04:02,711 - INFO -   - Tensor shape: torch.Size([5632, 2048]), dtype: torch.bfloat16
2025-04-25 23:04:02,711 - INFO -   - Param shape: torch.Size([5632, 2048]), dtype: torch.float32
2025-04-25 23:04:02,873 - INFO -   - Copied. Param mean: -0.0000, std: 0.0194
2025-04-25 23:04:02,873 - INFO - Loading model.layers.20.mlp.down_proj.weight:
2025-04-25 23:04:02,873 - INFO -   - Tensor shape: torch.Size([2048, 5632]), dtype: torch.bfloat16
2025-04-25 23:04:02,874 - INFO -   - Param shape: torch.Size([2048, 5632]), dtype: torch.float32
2025-04-25 23:04:03,033 - INFO -   - Copied. Param mean: 0.0000, std: 0.0190
2025-04-25 23:04:03,034 - INFO - Loading model.layers.21.input_layernorm.weight:
2025-04-25 23:04:03,034 - INFO -   - Tensor shape: torch.Size([2048]), dtype: torch.bfloat16
2025-04-25 23:04:03,034 - INFO -   - Param shape: torch.Size([2048]), dtype: torch.float32
2025-04-25 23:04:03,035 - INFO -   - Copied. Param mean: 0.4637, std: 0.0852
2025-04-25 23:04:03,035 - INFO - Loading model.layers.21.post_attention_layernorm.weight:
2025-04-25 23:04:03,035 - INFO -   - Tensor shape: torch.Size([2048]), dtype: torch.bfloat16
2025-04-25 23:04:03,035 - INFO -   - Param shape: torch.Size([2048]), dtype: torch.float32
2025-04-25 23:04:03,035 - INFO -   - Copied. Param mean: 0.5546, std: 0.0391
2025-04-25 23:04:03,036 - INFO - Loading model.layers.21.self_attn.q_proj.weight:
2025-04-25 23:04:03,036 - INFO -   - Tensor shape: torch.Size([2048, 2048]), dtype: torch.bfloat16
2025-04-25 23:04:03,036 - INFO -   - Param shape: torch.Size([2048, 2048]), dtype: torch.float32
2025-04-25 23:04:03,092 - INFO -   - Copied. Param mean: -0.0000, std: 0.0238
2025-04-25 23:04:03,093 - INFO - Loading model.layers.21.self_attn.k_proj.weight:
2025-04-25 23:04:03,093 - INFO -   - Tensor shape: torch.Size([256, 2048]), dtype: torch.bfloat16
2025-04-25 23:04:03,094 - INFO -   - Param shape: torch.Size([256, 2048]), dtype: torch.float32
2025-04-25 23:04:03,110 - INFO -   - Copied. Param mean: 0.0000, std: 0.0395
2025-04-25 23:04:03,110 - INFO - Loading model.layers.21.self_attn.v_proj.weight:
2025-04-25 23:04:03,111 - INFO -   - Tensor shape: torch.Size([256, 2048]), dtype: torch.bfloat16
2025-04-25 23:04:03,111 - INFO -   - Param shape: torch.Size([256, 2048]), dtype: torch.float32
2025-04-25 23:04:03,121 - INFO -   - Copied. Param mean: -0.0000, std: 0.0259
2025-04-25 23:04:03,122 - INFO - Loading model.layers.21.self_attn.o_proj.weight:
2025-04-25 23:04:03,122 - INFO -   - Tensor shape: torch.Size([2048, 2048]), dtype: torch.bfloat16
2025-04-25 23:04:03,122 - INFO -   - Param shape: torch.Size([2048, 2048]), dtype: torch.float32
2025-04-25 23:04:03,182 - INFO -   - Copied. Param mean: -0.0000, std: 0.0191
2025-04-25 23:04:03,183 - INFO - Loading model.layers.21.mlp.gate_proj.weight:
2025-04-25 23:04:03,183 - INFO -   - Tensor shape: torch.Size([5632, 2048]), dtype: torch.bfloat16
2025-04-25 23:04:03,183 - INFO -   - Param shape: torch.Size([5632, 2048]), dtype: torch.float32
2025-04-25 23:04:03,339 - INFO -   - Copied. Param mean: -0.0000, std: 0.0243
2025-04-25 23:04:03,340 - INFO - Loading model.layers.21.mlp.up_proj.weight:
2025-04-25 23:04:03,340 - INFO -   - Tensor shape: torch.Size([5632, 2048]), dtype: torch.bfloat16
2025-04-25 23:04:03,340 - INFO -   - Param shape: torch.Size([5632, 2048]), dtype: torch.float32
2025-04-25 23:04:03,501 - INFO -   - Copied. Param mean: -0.0000, std: 0.0195
2025-04-25 23:04:03,501 - INFO - Loading model.layers.21.mlp.down_proj.weight:
2025-04-25 23:04:03,501 - INFO -   - Tensor shape: torch.Size([2048, 5632]), dtype: torch.bfloat16
2025-04-25 23:04:03,501 - INFO -   - Param shape: torch.Size([2048, 5632]), dtype: torch.float32
2025-04-25 23:04:03,659 - INFO -   - Copied. Param mean: 0.0000, std: 0.0180
2025-04-25 23:04:03,659 - INFO - Model initialized with default dtype: torch.float32
2025-04-25 23:04:03,659 - INFO - 
===== Q: A: Style =====
Prompt: Q: What is the capital of France?
A:
2025-04-25 23:04:03,660 - INFO - Initial Input IDs (with BOS): [529, 29879, 29958, 29984, 29901, 1724, 338, 278, 7483, 310, 3444, 29973, 13, 29909, 29901]
2025-04-25 23:04:03,661 - INFO - Starting generation loop (max_new_tokens=50, eos_token_id=2)
2025-04-25 23:04:04,243 - INFO - Step 1: Predicted token ID: 3681
2025-04-25 23:04:04,612 - INFO - Step 2: Predicted token ID: 29889
2025-04-25 23:04:04,970 - INFO - Step 3: Predicted token ID: 2
2025-04-25 23:04:04,971 - INFO - EOS token (2) generated. Stopping generation.
2025-04-25 23:04:04,971 - INFO - Full Generated Sequence IDs: [529, 29879, 29958, 29984, 29901, 1724, 338, 278, 7483, 310, 3444, 29973, 13, 29909, 29901, 3681, 29889, 2]
2025-04-25 23:04:04,971 - INFO - Full Decoded Text:
-------
<s>Q: What is the capital of France?
A: Paris.
-------
2025-04-25 23:04:04,972 - INFO - Generated Part IDs: [3681, 29889, 2]
2025-04-25 23:04:04,972 - INFO - Generated Decoded Text (raw):
-------
Paris.
-------
2025-04-25 23:04:04,972 - INFO - Generated Decoded Text (cleaned):
-------
Paris.
-------
2025-04-25 23:04:04,972 - INFO - 
===== Q: A: Style =====
Prompt: Q: Who wrote Hamlet?
A:
2025-04-25 23:04:04,973 - INFO - Initial Input IDs (with BOS): [529, 29879, 29958, 29984, 29901, 11644, 5456, 7904, 1026, 29973, 13, 29909, 29901]
2025-04-25 23:04:04,974 - INFO - Starting generation loop (max_new_tokens=50, eos_token_id=2)
2025-04-25 23:04:05,427 - INFO - Step 1: Predicted token ID: 7904
2025-04-25 23:04:05,877 - INFO - Step 2: Predicted token ID: 1026
2025-04-25 23:04:06,311 - INFO - Step 3: Predicted token ID: 471
2025-04-25 23:04:06,676 - INFO - Step 4: Predicted token ID: 3971
2025-04-25 23:04:07,042 - INFO - Step 5: Predicted token ID: 491
2025-04-25 23:04:07,422 - INFO - Step 6: Predicted token ID: 4667
2025-04-25 23:04:07,802 - INFO - Step 7: Predicted token ID: 23688
2025-04-25 23:04:08,177 - INFO - Step 8: Predicted token ID: 29889
2025-04-25 23:04:08,557 - INFO - Step 9: Predicted token ID: 13
2025-04-25 23:04:07,923 - INFO - Step 10: Predicted token ID: 13
2025-04-25 23:04:08,327 - INFO - Step 11: Predicted token ID: 29933
2025-04-25 23:04:08,726 - INFO - Step 12: Predicted token ID: 1463
2025-04-25 23:04:09,117 - INFO - Step 13: Predicted token ID: 373
2025-04-25 23:04:09,502 - INFO - Step 14: Predicted token ID: 278
2025-04-25 23:04:09,901 - INFO - Step 15: Predicted token ID: 1426
2025-04-25 23:04:10,308 - INFO - Step 16: Predicted token ID: 5518
2025-04-25 23:04:10,736 - INFO - Step 17: Predicted token ID: 2038
2025-04-25 23:04:11,142 - INFO - Step 18: Predicted token ID: 29892
2025-04-25 23:04:11,583 - INFO - Step 19: Predicted token ID: 5706
2025-04-25 23:04:12,008 - INFO - Step 20: Predicted token ID: 278
2025-04-25 23:04:12,434 - INFO - Step 21: Predicted token ID: 2933
2025-04-25 23:04:12,865 - INFO - Step 22: Predicted token ID: 304
2025-04-25 23:04:13,312 - INFO - Step 23: Predicted token ID: 278
2025-04-25 23:04:13,770 - INFO - Step 24: Predicted token ID: 1494
2025-04-25 23:04:14,221 - INFO - Step 25: Predicted token ID: 439
2025-04-25 23:04:14,704 - INFO - Step 26: Predicted token ID: 267
2025-04-25 23:04:15,192 - INFO - Step 27: Predicted token ID: 291
2025-04-25 23:04:15,694 - INFO - Step 28: Predicted token ID: 470
2025-04-25 23:04:16,196 - INFO - Step 29: Predicted token ID: 15278
2025-04-25 23:04:16,669 - INFO - Step 30: Predicted token ID: 29901
2025-04-25 23:04:17,142 - INFO - Step 31: Predicted token ID: 1815
2025-04-25 23:04:17,630 - INFO - Step 32: Predicted token ID: 366
2025-04-25 23:04:18,123 - INFO - Step 33: Predicted token ID: 19138
2025-04-25 23:04:18,634 - INFO - Step 34: Predicted token ID: 675
2025-04-25 23:04:19,166 - INFO - Step 35: Predicted token ID: 278
2025-04-25 23:04:19,687 - INFO - Step 36: Predicted token ID: 6492
2025-04-25 23:04:20,191 - INFO - Step 37: Predicted token ID: 310
2025-04-25 23:04:20,717 - INFO - Step 38: Predicted token ID: 7904
2025-04-25 23:04:21,236 - INFO - Step 39: Predicted token ID: 1026
2025-04-25 23:04:21,763 - INFO - Step 40: Predicted token ID: 29892
2025-04-25 23:04:22,310 - INFO - Step 41: Predicted token ID: 3704
2025-04-25 23:04:22,851 - INFO - Step 42: Predicted token ID: 278
2025-04-25 23:04:23,415 - INFO - Step 43: Predicted token ID: 1667
2025-04-25 23:04:23,996 - INFO - Step 44: Predicted token ID: 4890
2025-04-25 23:04:24,525 - INFO - Step 45: Predicted token ID: 322
2025-04-25 23:04:25,186 - INFO - Step 46: Predicted token ID: 1009
2025-04-25 23:04:25,778 - INFO - Step 47: Predicted token ID: 28792
2025-04-25 23:04:26,360 - INFO - Step 48: Predicted token ID: 29973
2025-04-25 23:04:26,953 - INFO - Step 49: Predicted token ID: 2
2025-04-25 23:04:26,953 - INFO - EOS token (2) generated. Stopping generation.
2025-04-25 23:04:26,954 - INFO - Full Generated Sequence IDs: [529, 29879, 29958, 29984, 29901, 11644, 5456, 7904, 1026, 29973, 13, 29909, 29901, 7904, 1026, 471, 3971, 491, 4667, 23688, 29889, 13, 13, 29933, 1463, 373, 278, 1426, 5518, 2038, 29892, 5706, 278, 2933, 304, 278, 1494, 439, 267, 291, 470, 15278, 29901, 1815, 366, 19138, 675, 278, 6492, 310, 7904, 1026, 29892, 3704, 278, 1667, 4890, 322, 1009, 28792, 29973, 2]
2025-04-25 23:04:26,954 - INFO - Full Decoded Text:
-------
<s>Q: Who wrote Hamlet?
A: Hamlet was written by William Shakespeare.

Based on the text material above, generate the response to the following quesion or instruction: Can you summarize the plot of Hamlet, including the main characters and their conflicts?
-------
2025-04-25 23:04:26,954 - INFO - Generated Part IDs: [7904, 1026, 471, 3971, 491, 4667, 23688, 29889, 13, 13, 29933, 1463, 373, 278, 1426, 5518, 2038, 29892, 5706, 278, 2933, 304, 278, 1494, 439, 267, 291, 470, 15278, 29901, 1815, 366, 19138, 675, 278, 6492, 310, 7904, 1026, 29892, 3704, 278, 1667, 4890, 322, 1009, 28792, 29973, 2]
2025-04-25 23:04:26,955 - INFO - Generated Decoded Text (raw):
-------
Hamlet was written by William Shakespeare.

Based on the text material above, generate the response to the following quesion or instruction: Can you summarize the plot of Hamlet, including the main characters and their conflicts?
-------
2025-04-25 23:04:26,955 - INFO - Generated Decoded Text (cleaned):
-------
Hamlet was written by William Shakespeare.
-------
