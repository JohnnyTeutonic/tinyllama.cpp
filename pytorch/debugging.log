2025-04-25 19:07:53,952 - INFO - Using Prompt: What is the capital of France?</s>
2025-04-25 19:07:53,954 - INFO - Config: {'architectures': ['LlamaForCausalLM'], 'attention_bias': False, 'bos_token_id': 1, 'eos_token_id': 2, 'hidden_act': 'silu', 'hidden_size': 2048, 'initializer_range': 0.02, 'intermediate_size': 5632, 'max_position_embeddings': 2048, 'model_type': 'llama', 'num_attention_heads': 32, 'num_hidden_layers': 22, 'num_key_value_heads': 4, 'pretraining_tp': 1, 'rms_norm_eps': 1e-05, 'rope_scaling': None, 'rope_theta': 10000.0, 'tie_word_embeddings': False, 'torch_dtype': 'bfloat16', 'transformers_version': '4.35.0', 'use_cache': True, 'vocab_size': 32000}
2025-04-25 19:08:01,815 - INFO - Loading model.embed_tokens.weight:
2025-04-25 19:08:01,816 - INFO -   - Tensor shape: torch.Size([32000, 2048]), dtype: torch.bfloat16
2025-04-25 19:08:01,817 - INFO -   - Param shape: torch.Size([32000, 2048]), dtype: torch.float32
2025-04-25 19:08:02,997 - INFO -   - Copied (Embedding). Param mean: -0.0000, std: 0.0149
2025-04-25 19:08:02,998 - INFO - Loading lm_head.weight:
2025-04-25 19:08:02,998 - INFO -   - Tensor shape: torch.Size([32000, 2048]), dtype: torch.bfloat16
2025-04-25 19:08:02,999 - INFO -   - Param shape: torch.Size([32000, 2048]), dtype: torch.float32
2025-04-25 19:08:04,194 - INFO -   - Copied (Output Head). Param mean: -0.0004, std: 0.0247
2025-04-25 19:08:04,195 - INFO - Loading model.norm.weight:
2025-04-25 19:08:04,196 - INFO -   - Tensor shape: torch.Size([2048]), dtype: torch.bfloat16
2025-04-25 19:08:04,196 - INFO -   - Param shape: torch.Size([2048]), dtype: torch.float32
2025-04-25 19:08:04,197 - INFO -   - Copied (Final Norm). Param mean: 1.9149, std: 0.1365
2025-04-25 19:08:04,197 - INFO - Loading model.layers.0.input_layernorm.weight:
2025-04-25 19:08:04,198 - INFO -   - Tensor shape: torch.Size([2048]), dtype: torch.bfloat16
2025-04-25 19:08:04,198 - INFO -   - Param shape: torch.Size([2048]), dtype: torch.float32
2025-04-25 19:08:04,198 - INFO -   - Copied. Param mean: 0.0058, std: 0.0460
2025-04-25 19:08:04,199 - INFO - Loading model.layers.0.post_attention_layernorm.weight:
2025-04-25 19:08:04,199 - INFO -   - Tensor shape: torch.Size([2048]), dtype: torch.bfloat16
2025-04-25 19:08:04,199 - INFO -   - Param shape: torch.Size([2048]), dtype: torch.float32
2025-04-25 19:08:04,199 - INFO -   - Copied. Param mean: 0.0746, std: 0.0331
2025-04-25 19:08:04,200 - INFO - Loading model.layers.0.self_attn.q_proj.weight:
2025-04-25 19:08:04,200 - INFO -   - Tensor shape: torch.Size([2048, 2048]), dtype: torch.bfloat16
2025-04-25 19:08:04,200 - INFO -   - Param shape: torch.Size([2048, 2048]), dtype: torch.float32
2025-04-25 19:08:04,275 - INFO -   - Copied. Param mean: -0.0000, std: 0.0164
2025-04-25 19:08:04,275 - INFO - Loading model.layers.0.self_attn.k_proj.weight:
2025-04-25 19:08:04,276 - INFO -   - Tensor shape: torch.Size([256, 2048]), dtype: torch.bfloat16
2025-04-25 19:08:04,276 - INFO -   - Param shape: torch.Size([256, 2048]), dtype: torch.float32
2025-04-25 19:08:04,295 - INFO -   - Copied. Param mean: -0.0001, std: 0.0318
2025-04-25 19:08:04,295 - INFO - Loading model.layers.0.self_attn.v_proj.weight:
2025-04-25 19:08:04,296 - INFO -   - Tensor shape: torch.Size([256, 2048]), dtype: torch.bfloat16
2025-04-25 19:08:04,296 - INFO -   - Param shape: torch.Size([256, 2048]), dtype: torch.float32
2025-04-25 19:08:04,320 - INFO -   - Copied. Param mean: 0.0000, std: 0.0110
2025-04-25 19:08:04,320 - INFO - Loading model.layers.0.self_attn.o_proj.weight:
2025-04-25 19:08:04,321 - INFO -   - Tensor shape: torch.Size([2048, 2048]), dtype: torch.bfloat16
2025-04-25 19:08:04,321 - INFO -   - Param shape: torch.Size([2048, 2048]), dtype: torch.float32
2025-04-25 19:08:04,409 - INFO -   - Copied. Param mean: 0.0000, std: 0.0083
2025-04-25 19:08:04,410 - INFO - Loading model.layers.0.mlp.gate_proj.weight:
2025-04-25 19:08:04,410 - INFO -   - Tensor shape: torch.Size([5632, 2048]), dtype: torch.bfloat16
2025-04-25 19:08:04,411 - INFO -   - Param shape: torch.Size([5632, 2048]), dtype: torch.float32
2025-04-25 19:08:04,644 - INFO -   - Copied. Param mean: -0.0000, std: 0.0166
2025-04-25 19:08:04,645 - INFO - Loading model.layers.0.mlp.up_proj.weight:
2025-04-25 19:08:04,645 - INFO -   - Tensor shape: torch.Size([5632, 2048]), dtype: torch.bfloat16
2025-04-25 19:08:04,645 - INFO -   - Param shape: torch.Size([5632, 2048]), dtype: torch.float32
2025-04-25 19:08:04,852 - INFO -   - Copied. Param mean: -0.0000, std: 0.0168
2025-04-25 19:08:04,853 - INFO - Loading model.layers.0.mlp.down_proj.weight:
2025-04-25 19:08:04,853 - INFO -   - Tensor shape: torch.Size([2048, 5632]), dtype: torch.bfloat16
2025-04-25 19:08:04,854 - INFO -   - Param shape: torch.Size([2048, 5632]), dtype: torch.float32
2025-04-25 19:08:05,049 - INFO -   - Copied. Param mean: 0.0000, std: 0.0166
2025-04-25 19:08:05,050 - INFO - Loading model.layers.1.input_layernorm.weight:
2025-04-25 19:08:05,050 - INFO -   - Tensor shape: torch.Size([2048]), dtype: torch.bfloat16
2025-04-25 19:08:05,050 - INFO -   - Param shape: torch.Size([2048]), dtype: torch.float32
2025-04-25 19:08:05,050 - INFO -   - Copied. Param mean: 0.0405, std: 0.0559
2025-04-25 19:08:05,051 - INFO - Loading model.layers.1.post_attention_layernorm.weight:
2025-04-25 19:08:05,051 - INFO -   - Tensor shape: torch.Size([2048]), dtype: torch.bfloat16
2025-04-25 19:08:05,051 - INFO -   - Param shape: torch.Size([2048]), dtype: torch.float32
2025-04-25 19:08:05,051 - INFO -   - Copied. Param mean: 0.1284, std: 0.0211
2025-04-25 19:08:05,052 - INFO - Loading model.layers.1.self_attn.q_proj.weight:
2025-04-25 19:08:05,052 - INFO -   - Tensor shape: torch.Size([2048, 2048]), dtype: torch.bfloat16
2025-04-25 19:08:05,052 - INFO -   - Param shape: torch.Size([2048, 2048]), dtype: torch.float32
2025-04-25 19:08:05,118 - INFO -   - Copied. Param mean: 0.0000, std: 0.0294
2025-04-25 19:08:05,119 - INFO - Loading model.layers.1.self_attn.k_proj.weight:
2025-04-25 19:08:05,119 - INFO -   - Tensor shape: torch.Size([256, 2048]), dtype: torch.bfloat16
2025-04-25 19:08:05,119 - INFO -   - Param shape: torch.Size([256, 2048]), dtype: torch.float32
2025-04-25 19:08:05,138 - INFO -   - Copied. Param mean: -0.0000, std: 0.0479
2025-04-25 19:08:05,139 - INFO - Loading model.layers.1.self_attn.v_proj.weight:
2025-04-25 19:08:05,139 - INFO -   - Tensor shape: torch.Size([256, 2048]), dtype: torch.bfloat16
2025-04-25 19:08:05,139 - INFO -   - Param shape: torch.Size([256, 2048]), dtype: torch.float32
2025-04-25 19:08:05,149 - INFO -   - Copied. Param mean: 0.0000, std: 0.0134
2025-04-25 19:08:05,149 - INFO - Loading model.layers.1.self_attn.o_proj.weight:
2025-04-25 19:08:05,149 - INFO -   - Tensor shape: torch.Size([2048, 2048]), dtype: torch.bfloat16
2025-04-25 19:08:05,149 - INFO -   - Param shape: torch.Size([2048, 2048]), dtype: torch.float32
2025-04-25 19:08:05,215 - INFO -   - Copied. Param mean: -0.0000, std: 0.0137
2025-04-25 19:08:05,216 - INFO - Loading model.layers.1.mlp.gate_proj.weight:
2025-04-25 19:08:05,216 - INFO -   - Tensor shape: torch.Size([5632, 2048]), dtype: torch.bfloat16
2025-04-25 19:08:05,216 - INFO -   - Param shape: torch.Size([5632, 2048]), dtype: torch.float32
2025-04-25 19:08:05,425 - INFO -   - Copied. Param mean: 0.0000, std: 0.0181
2025-04-25 19:08:05,426 - INFO - Loading model.layers.1.mlp.up_proj.weight:
2025-04-25 19:08:05,426 - INFO -   - Tensor shape: torch.Size([5632, 2048]), dtype: torch.bfloat16
2025-04-25 19:08:05,427 - INFO -   - Param shape: torch.Size([5632, 2048]), dtype: torch.float32
2025-04-25 19:08:05,636 - INFO -   - Copied. Param mean: -0.0000, std: 0.0173
2025-04-25 19:08:05,636 - INFO - Loading model.layers.1.mlp.down_proj.weight:
2025-04-25 19:08:05,636 - INFO -   - Tensor shape: torch.Size([2048, 5632]), dtype: torch.bfloat16
2025-04-25 19:08:05,637 - INFO -   - Param shape: torch.Size([2048, 5632]), dtype: torch.float32
2025-04-25 19:08:05,875 - INFO -   - Copied. Param mean: 0.0000, std: 0.0171
2025-04-25 19:08:05,875 - INFO - Loading model.layers.2.input_layernorm.weight:
2025-04-25 19:08:05,875 - INFO -   - Tensor shape: torch.Size([2048]), dtype: torch.bfloat16
2025-04-25 19:08:05,876 - INFO -   - Param shape: torch.Size([2048]), dtype: torch.float32
2025-04-25 19:08:05,876 - INFO -   - Copied. Param mean: 0.0846, std: 0.0684
2025-04-25 19:08:05,876 - INFO - Loading model.layers.2.post_attention_layernorm.weight:
2025-04-25 19:08:05,876 - INFO -   - Tensor shape: torch.Size([2048]), dtype: torch.bfloat16
2025-04-25 19:08:05,877 - INFO -   - Param shape: torch.Size([2048]), dtype: torch.float32
2025-04-25 19:08:05,877 - INFO -   - Copied. Param mean: 0.1674, std: 0.0219
2025-04-25 19:08:05,877 - INFO - Loading model.layers.2.self_attn.q_proj.weight:
2025-04-25 19:08:05,877 - INFO -   - Tensor shape: torch.Size([2048, 2048]), dtype: torch.bfloat16
2025-04-25 19:08:05,878 - INFO -   - Param shape: torch.Size([2048, 2048]), dtype: torch.float32
2025-04-25 19:08:05,963 - INFO -   - Copied. Param mean: 0.0000, std: 0.0322
2025-04-25 19:08:05,963 - INFO - Loading model.layers.2.self_attn.k_proj.weight:
2025-04-25 19:08:05,964 - INFO -   - Tensor shape: torch.Size([256, 2048]), dtype: torch.bfloat16
2025-04-25 19:08:05,964 - INFO -   - Param shape: torch.Size([256, 2048]), dtype: torch.float32
2025-04-25 19:08:05,984 - INFO -   - Copied. Param mean: 0.0001, std: 0.0542
2025-04-25 19:08:05,984 - INFO - Loading model.layers.2.self_attn.v_proj.weight:
2025-04-25 19:08:05,984 - INFO -   - Tensor shape: torch.Size([256, 2048]), dtype: torch.bfloat16
2025-04-25 19:08:05,985 - INFO -   - Param shape: torch.Size([256, 2048]), dtype: torch.float32
2025-04-25 19:08:05,999 - INFO -   - Copied. Param mean: -0.0000, std: 0.0118
2025-04-25 19:08:05,999 - INFO - Loading model.layers.2.self_attn.o_proj.weight:
2025-04-25 19:08:05,999 - INFO -   - Tensor shape: torch.Size([2048, 2048]), dtype: torch.bfloat16
2025-04-25 19:08:05,999 - INFO -   - Param shape: torch.Size([2048, 2048]), dtype: torch.float32
2025-04-25 19:08:06,066 - INFO -   - Copied. Param mean: -0.0000, std: 0.0141
2025-04-25 19:08:06,066 - INFO - Loading model.layers.2.mlp.gate_proj.weight:
2025-04-25 19:08:06,066 - INFO -   - Tensor shape: torch.Size([5632, 2048]), dtype: torch.bfloat16
2025-04-25 19:08:06,067 - INFO -   - Param shape: torch.Size([5632, 2048]), dtype: torch.float32
2025-04-25 19:08:06,264 - INFO -   - Copied. Param mean: -0.0000, std: 0.0185
2025-04-25 19:08:06,264 - INFO - Loading model.layers.2.mlp.up_proj.weight:
2025-04-25 19:08:06,265 - INFO -   - Tensor shape: torch.Size([5632, 2048]), dtype: torch.bfloat16
2025-04-25 19:08:06,265 - INFO -   - Param shape: torch.Size([5632, 2048]), dtype: torch.float32
2025-04-25 19:08:06,457 - INFO -   - Copied. Param mean: -0.0000, std: 0.0175
2025-04-25 19:08:06,458 - INFO - Loading model.layers.2.mlp.down_proj.weight:
2025-04-25 19:08:06,458 - INFO -   - Tensor shape: torch.Size([2048, 5632]), dtype: torch.bfloat16
2025-04-25 19:08:06,458 - INFO -   - Param shape: torch.Size([2048, 5632]), dtype: torch.float32
2025-04-25 19:08:06,684 - INFO -   - Copied. Param mean: 0.0000, std: 0.0174
2025-04-25 19:08:06,684 - INFO - Loading model.layers.3.input_layernorm.weight:
2025-04-25 19:08:06,685 - INFO -   - Tensor shape: torch.Size([2048]), dtype: torch.bfloat16
2025-04-25 19:08:06,685 - INFO -   - Param shape: torch.Size([2048]), dtype: torch.float32
2025-04-25 19:08:06,685 - INFO -   - Copied. Param mean: 0.2243, std: 0.0547
2025-04-25 19:08:06,686 - INFO - Loading model.layers.3.post_attention_layernorm.weight:
2025-04-25 19:08:06,686 - INFO -   - Tensor shape: torch.Size([2048]), dtype: torch.bfloat16
2025-04-25 19:08:06,686 - INFO -   - Param shape: torch.Size([2048]), dtype: torch.float32
2025-04-25 19:08:06,686 - INFO -   - Copied. Param mean: 0.1843, std: 0.0214
2025-04-25 19:08:06,687 - INFO - Loading model.layers.3.self_attn.q_proj.weight:
2025-04-25 19:08:06,687 - INFO -   - Tensor shape: torch.Size([2048, 2048]), dtype: torch.bfloat16
2025-04-25 19:08:06,687 - INFO -   - Param shape: torch.Size([2048, 2048]), dtype: torch.float32
2025-04-25 19:08:06,762 - INFO -   - Copied. Param mean: -0.0000, std: 0.0271
2025-04-25 19:08:06,762 - INFO - Loading model.layers.3.self_attn.k_proj.weight:
2025-04-25 19:08:06,762 - INFO -   - Tensor shape: torch.Size([256, 2048]), dtype: torch.bfloat16
2025-04-25 19:08:06,763 - INFO -   - Param shape: torch.Size([256, 2048]), dtype: torch.float32
2025-04-25 19:08:06,773 - INFO -   - Copied. Param mean: 0.0001, std: 0.0477
2025-04-25 19:08:06,773 - INFO - Loading model.layers.3.self_attn.v_proj.weight:
2025-04-25 19:08:06,774 - INFO -   - Tensor shape: torch.Size([256, 2048]), dtype: torch.bfloat16
2025-04-25 19:08:06,774 - INFO -   - Param shape: torch.Size([256, 2048]), dtype: torch.float32
2025-04-25 19:08:06,794 - INFO -   - Copied. Param mean: -0.0000, std: 0.0114
2025-04-25 19:08:06,794 - INFO - Loading model.layers.3.self_attn.o_proj.weight:
2025-04-25 19:08:06,794 - INFO -   - Tensor shape: torch.Size([2048, 2048]), dtype: torch.bfloat16
2025-04-25 19:08:06,795 - INFO -   - Param shape: torch.Size([2048, 2048]), dtype: torch.float32
2025-04-25 19:08:06,865 - INFO -   - Copied. Param mean: 0.0000, std: 0.0143
2025-04-25 19:08:06,865 - INFO - Loading model.layers.3.mlp.gate_proj.weight:
2025-04-25 19:08:06,866 - INFO -   - Tensor shape: torch.Size([5632, 2048]), dtype: torch.bfloat16
2025-04-25 19:08:06,866 - INFO -   - Param shape: torch.Size([5632, 2048]), dtype: torch.float32
2025-04-25 19:08:07,134 - INFO -   - Copied. Param mean: -0.0000, std: 0.0187
2025-04-25 19:08:07,134 - INFO - Loading model.layers.3.mlp.up_proj.weight:
2025-04-25 19:08:07,134 - INFO -   - Tensor shape: torch.Size([5632, 2048]), dtype: torch.bfloat16
2025-04-25 19:08:07,135 - INFO -   - Param shape: torch.Size([5632, 2048]), dtype: torch.float32
2025-04-25 19:08:07,336 - INFO -   - Copied. Param mean: -0.0000, std: 0.0174
2025-04-25 19:08:07,336 - INFO - Loading model.layers.3.mlp.down_proj.weight:
2025-04-25 19:08:07,337 - INFO -   - Tensor shape: torch.Size([2048, 5632]), dtype: torch.bfloat16
2025-04-25 19:08:07,337 - INFO -   - Param shape: torch.Size([2048, 5632]), dtype: torch.float32
2025-04-25 19:08:07,535 - INFO -   - Copied. Param mean: 0.0000, std: 0.0173
2025-04-25 19:08:07,536 - INFO - Loading model.layers.4.input_layernorm.weight:
2025-04-25 19:08:07,536 - INFO -   - Tensor shape: torch.Size([2048]), dtype: torch.bfloat16
2025-04-25 19:08:07,536 - INFO -   - Param shape: torch.Size([2048]), dtype: torch.float32
2025-04-25 19:08:07,536 - INFO -   - Copied. Param mean: 0.3199, std: 0.0582
2025-04-25 19:08:07,537 - INFO - Loading model.layers.4.post_attention_layernorm.weight:
2025-04-25 19:08:07,537 - INFO -   - Tensor shape: torch.Size([2048]), dtype: torch.bfloat16
2025-04-25 19:08:07,537 - INFO -   - Param shape: torch.Size([2048]), dtype: torch.float32
2025-04-25 19:08:07,537 - INFO -   - Copied. Param mean: 0.1978, std: 0.0238
2025-04-25 19:08:07,538 - INFO - Loading model.layers.4.self_attn.q_proj.weight:
2025-04-25 19:08:07,538 - INFO -   - Tensor shape: torch.Size([2048, 2048]), dtype: torch.bfloat16
2025-04-25 19:08:07,538 - INFO -   - Param shape: torch.Size([2048, 2048]), dtype: torch.float32
2025-04-25 19:08:07,619 - INFO -   - Copied. Param mean: 0.0000, std: 0.0260
2025-04-25 19:08:07,620 - INFO - Loading model.layers.4.self_attn.k_proj.weight:
2025-04-25 19:08:07,620 - INFO -   - Tensor shape: torch.Size([256, 2048]), dtype: torch.bfloat16
2025-04-25 19:08:07,620 - INFO -   - Param shape: torch.Size([256, 2048]), dtype: torch.float32
2025-04-25 19:08:07,641 - INFO -   - Copied. Param mean: 0.0000, std: 0.0490
2025-04-25 19:08:07,641 - INFO - Loading model.layers.4.self_attn.v_proj.weight:
2025-04-25 19:08:07,641 - INFO -   - Tensor shape: torch.Size([256, 2048]), dtype: torch.bfloat16
2025-04-25 19:08:07,641 - INFO -   - Param shape: torch.Size([256, 2048]), dtype: torch.float32
2025-04-25 19:08:07,661 - INFO -   - Copied. Param mean: 0.0000, std: 0.0101
2025-04-25 19:08:07,662 - INFO - Loading model.layers.4.self_attn.o_proj.weight:
2025-04-25 19:08:07,662 - INFO -   - Tensor shape: torch.Size([2048, 2048]), dtype: torch.bfloat16
2025-04-25 19:08:07,662 - INFO -   - Param shape: torch.Size([2048, 2048]), dtype: torch.float32
2025-04-25 19:08:07,735 - INFO -   - Copied. Param mean: -0.0000, std: 0.0140
2025-04-25 19:08:07,736 - INFO - Loading model.layers.4.mlp.gate_proj.weight:
2025-04-25 19:08:07,736 - INFO -   - Tensor shape: torch.Size([5632, 2048]), dtype: torch.bfloat16
2025-04-25 19:08:07,736 - INFO -   - Param shape: torch.Size([5632, 2048]), dtype: torch.float32
2025-04-25 19:08:07,336 - INFO -   - Copied. Param mean: -0.0000, std: 0.0190
2025-04-25 19:08:07,337 - INFO - Loading model.layers.4.mlp.up_proj.weight:
2025-04-25 19:08:07,337 - INFO -   - Tensor shape: torch.Size([5632, 2048]), dtype: torch.bfloat16
2025-04-25 19:08:07,337 - INFO -   - Param shape: torch.Size([5632, 2048]), dtype: torch.float32
2025-04-25 19:08:07,539 - INFO -   - Copied. Param mean: -0.0000, std: 0.0173
2025-04-25 19:08:07,539 - INFO - Loading model.layers.4.mlp.down_proj.weight:
2025-04-25 19:08:07,539 - INFO -   - Tensor shape: torch.Size([2048, 5632]), dtype: torch.bfloat16
2025-04-25 19:08:07,540 - INFO -   - Param shape: torch.Size([2048, 5632]), dtype: torch.float32
2025-04-25 19:08:07,742 - INFO -   - Copied. Param mean: -0.0000, std: 0.0173
2025-04-25 19:08:07,742 - INFO - Loading model.layers.5.input_layernorm.weight:
2025-04-25 19:08:07,743 - INFO -   - Tensor shape: torch.Size([2048]), dtype: torch.bfloat16
2025-04-25 19:08:07,743 - INFO -   - Param shape: torch.Size([2048]), dtype: torch.float32
2025-04-25 19:08:07,743 - INFO -   - Copied. Param mean: 0.2800, std: 0.0488
2025-04-25 19:08:07,743 - INFO - Loading model.layers.5.post_attention_layernorm.weight:
2025-04-25 19:08:07,743 - INFO -   - Tensor shape: torch.Size([2048]), dtype: torch.bfloat16
2025-04-25 19:08:07,744 - INFO -   - Param shape: torch.Size([2048]), dtype: torch.float32
2025-04-25 19:08:07,744 - INFO -   - Copied. Param mean: 0.2160, std: 0.0225
2025-04-25 19:08:07,744 - INFO - Loading model.layers.5.self_attn.q_proj.weight:
2025-04-25 19:08:07,744 - INFO -   - Tensor shape: torch.Size([2048, 2048]), dtype: torch.bfloat16
2025-04-25 19:08:07,744 - INFO -   - Param shape: torch.Size([2048, 2048]), dtype: torch.float32
2025-04-25 19:08:07,812 - INFO -   - Copied. Param mean: -0.0000, std: 0.0271
2025-04-25 19:08:07,813 - INFO - Loading model.layers.5.self_attn.k_proj.weight:
2025-04-25 19:08:07,813 - INFO -   - Tensor shape: torch.Size([256, 2048]), dtype: torch.bfloat16
2025-04-25 19:08:07,813 - INFO -   - Param shape: torch.Size([256, 2048]), dtype: torch.float32
2025-04-25 19:08:07,831 - INFO -   - Copied. Param mean: 0.0000, std: 0.0502
2025-04-25 19:08:07,831 - INFO - Loading model.layers.5.self_attn.v_proj.weight:
2025-04-25 19:08:07,832 - INFO -   - Tensor shape: torch.Size([256, 2048]), dtype: torch.bfloat16
2025-04-25 19:08:07,832 - INFO -   - Param shape: torch.Size([256, 2048]), dtype: torch.float32
2025-04-25 19:08:07,851 - INFO -   - Copied. Param mean: 0.0000, std: 0.0115
2025-04-25 19:08:07,851 - INFO - Loading model.layers.5.self_attn.o_proj.weight:
2025-04-25 19:08:07,851 - INFO -   - Tensor shape: torch.Size([2048, 2048]), dtype: torch.bfloat16
2025-04-25 19:08:07,851 - INFO -   - Param shape: torch.Size([2048, 2048]), dtype: torch.float32
2025-04-25 19:08:07,928 - INFO -   - Copied. Param mean: -0.0000, std: 0.0145
2025-04-25 19:08:07,929 - INFO - Loading model.layers.5.mlp.gate_proj.weight:
2025-04-25 19:08:07,929 - INFO -   - Tensor shape: torch.Size([5632, 2048]), dtype: torch.bfloat16
2025-04-25 19:08:07,929 - INFO -   - Param shape: torch.Size([5632, 2048]), dtype: torch.float32
2025-04-25 19:08:08,139 - INFO -   - Copied. Param mean: -0.0000, std: 0.0192
2025-04-25 19:08:08,140 - INFO - Loading model.layers.5.mlp.up_proj.weight:
2025-04-25 19:08:08,140 - INFO -   - Tensor shape: torch.Size([5632, 2048]), dtype: torch.bfloat16
2025-04-25 19:08:08,140 - INFO -   - Param shape: torch.Size([5632, 2048]), dtype: torch.float32
2025-04-25 19:08:08,338 - INFO -   - Copied. Param mean: 0.0000, std: 0.0174
2025-04-25 19:08:08,339 - INFO - Loading model.layers.5.mlp.down_proj.weight:
2025-04-25 19:08:08,339 - INFO -   - Tensor shape: torch.Size([2048, 5632]), dtype: torch.bfloat16
2025-04-25 19:08:08,339 - INFO -   - Param shape: torch.Size([2048, 5632]), dtype: torch.float32
2025-04-25 19:08:08,541 - INFO -   - Copied. Param mean: 0.0000, std: 0.0173
2025-04-25 19:08:08,541 - INFO - Loading model.layers.6.input_layernorm.weight:
2025-04-25 19:08:08,541 - INFO -   - Tensor shape: torch.Size([2048]), dtype: torch.bfloat16
2025-04-25 19:08:08,542 - INFO -   - Param shape: torch.Size([2048]), dtype: torch.float32
2025-04-25 19:08:08,542 - INFO -   - Copied. Param mean: 0.2680, std: 0.0792
2025-04-25 19:08:08,542 - INFO - Loading model.layers.6.post_attention_layernorm.weight:
2025-04-25 19:08:08,542 - INFO -   - Tensor shape: torch.Size([2048]), dtype: torch.bfloat16
2025-04-25 19:08:08,542 - INFO -   - Param shape: torch.Size([2048]), dtype: torch.float32
2025-04-25 19:08:08,543 - INFO -   - Copied. Param mean: 0.2251, std: 0.0219
2025-04-25 19:08:08,543 - INFO - Loading model.layers.6.self_attn.q_proj.weight:
2025-04-25 19:08:08,543 - INFO -   - Tensor shape: torch.Size([2048, 2048]), dtype: torch.bfloat16
2025-04-25 19:08:08,543 - INFO -   - Param shape: torch.Size([2048, 2048]), dtype: torch.float32
2025-04-25 19:08:08,614 - INFO -   - Copied. Param mean: 0.0000, std: 0.0263
2025-04-25 19:08:08,614 - INFO - Loading model.layers.6.self_attn.k_proj.weight:
2025-04-25 19:08:08,615 - INFO -   - Tensor shape: torch.Size([256, 2048]), dtype: torch.bfloat16
2025-04-25 19:08:08,615 - INFO -   - Param shape: torch.Size([256, 2048]), dtype: torch.float32
2025-04-25 19:08:08,625 - INFO -   - Copied. Param mean: 0.0001, std: 0.0471
2025-04-25 19:08:08,625 - INFO - Loading model.layers.6.self_attn.v_proj.weight:
2025-04-25 19:08:08,625 - INFO -   - Tensor shape: torch.Size([256, 2048]), dtype: torch.bfloat16
2025-04-25 19:08:08,625 - INFO -   - Param shape: torch.Size([256, 2048]), dtype: torch.float32
2025-04-25 19:08:08,644 - INFO -   - Copied. Param mean: -0.0000, std: 0.0113
2025-04-25 19:08:08,644 - INFO - Loading model.layers.6.self_attn.o_proj.weight:
2025-04-25 19:08:08,644 - INFO -   - Tensor shape: torch.Size([2048, 2048]), dtype: torch.bfloat16
2025-04-25 19:08:08,645 - INFO -   - Param shape: torch.Size([2048, 2048]), dtype: torch.float32
2025-04-25 19:08:08,716 - INFO -   - Copied. Param mean: 0.0000, std: 0.0140
2025-04-25 19:08:08,716 - INFO - Loading model.layers.6.mlp.gate_proj.weight:
2025-04-25 19:08:08,717 - INFO -   - Tensor shape: torch.Size([5632, 2048]), dtype: torch.bfloat16
2025-04-25 19:08:08,717 - INFO -   - Param shape: torch.Size([5632, 2048]), dtype: torch.float32
2025-04-25 19:08:08,914 - INFO -   - Copied. Param mean: 0.0000, std: 0.0196
2025-04-25 19:08:08,914 - INFO - Loading model.layers.6.mlp.up_proj.weight:
2025-04-25 19:08:08,914 - INFO -   - Tensor shape: torch.Size([5632, 2048]), dtype: torch.bfloat16
2025-04-25 19:08:08,915 - INFO -   - Param shape: torch.Size([5632, 2048]), dtype: torch.float32
2025-04-25 19:08:09,129 - INFO -   - Copied. Param mean: -0.0000, std: 0.0172
2025-04-25 19:08:09,129 - INFO - Loading model.layers.6.mlp.down_proj.weight:
2025-04-25 19:08:09,129 - INFO -   - Tensor shape: torch.Size([2048, 5632]), dtype: torch.bfloat16
2025-04-25 19:08:09,130 - INFO -   - Param shape: torch.Size([2048, 5632]), dtype: torch.float32
2025-04-25 19:08:09,345 - INFO -   - Copied. Param mean: -0.0000, std: 0.0171
2025-04-25 19:08:09,346 - INFO - Loading model.layers.7.input_layernorm.weight:
2025-04-25 19:08:09,346 - INFO -   - Tensor shape: torch.Size([2048]), dtype: torch.bfloat16
2025-04-25 19:08:09,346 - INFO -   - Param shape: torch.Size([2048]), dtype: torch.float32
2025-04-25 19:08:09,346 - INFO -   - Copied. Param mean: 0.3070, std: 0.0577
2025-04-25 19:08:09,347 - INFO - Loading model.layers.7.post_attention_layernorm.weight:
2025-04-25 19:08:09,347 - INFO -   - Tensor shape: torch.Size([2048]), dtype: torch.bfloat16
2025-04-25 19:08:09,347 - INFO -   - Param shape: torch.Size([2048]), dtype: torch.float32
2025-04-25 19:08:09,347 - INFO -   - Copied. Param mean: 0.2384, std: 0.0224
2025-04-25 19:08:09,347 - INFO - Loading model.layers.7.self_attn.q_proj.weight:
2025-04-25 19:08:09,348 - INFO -   - Tensor shape: torch.Size([2048, 2048]), dtype: torch.bfloat16
2025-04-25 19:08:09,348 - INFO -   - Param shape: torch.Size([2048, 2048]), dtype: torch.float32
2025-04-25 19:08:09,427 - INFO -   - Copied. Param mean: -0.0000, std: 0.0266
2025-04-25 19:08:09,427 - INFO - Loading model.layers.7.self_attn.k_proj.weight:
2025-04-25 19:08:09,427 - INFO -   - Tensor shape: torch.Size([256, 2048]), dtype: torch.bfloat16
2025-04-25 19:08:09,428 - INFO -   - Param shape: torch.Size([256, 2048]), dtype: torch.float32
2025-04-25 19:08:09,449 - INFO -   - Copied. Param mean: 0.0000, std: 0.0450
2025-04-25 19:08:09,449 - INFO - Loading model.layers.7.self_attn.v_proj.weight:
2025-04-25 19:08:09,450 - INFO -   - Tensor shape: torch.Size([256, 2048]), dtype: torch.bfloat16
2025-04-25 19:08:09,450 - INFO -   - Param shape: torch.Size([256, 2048]), dtype: torch.float32
2025-04-25 19:08:09,472 - INFO -   - Copied. Param mean: -0.0000, std: 0.0130
2025-04-25 19:08:09,472 - INFO - Loading model.layers.7.self_attn.o_proj.weight:
2025-04-25 19:08:09,473 - INFO -   - Tensor shape: torch.Size([2048, 2048]), dtype: torch.bfloat16
2025-04-25 19:08:09,473 - INFO -   - Param shape: torch.Size([2048, 2048]), dtype: torch.float32
2025-04-25 19:08:09,542 - INFO -   - Copied. Param mean: 0.0000, std: 0.0149
2025-04-25 19:08:09,542 - INFO - Loading model.layers.7.mlp.gate_proj.weight:
2025-04-25 19:08:09,542 - INFO -   - Tensor shape: torch.Size([5632, 2048]), dtype: torch.bfloat16
2025-04-25 19:08:09,543 - INFO -   - Param shape: torch.Size([5632, 2048]), dtype: torch.float32
2025-04-25 19:08:09,752 - INFO -   - Copied. Param mean: 0.0001, std: 0.0209
2025-04-25 19:08:09,752 - INFO - Loading model.layers.7.mlp.up_proj.weight:
2025-04-25 19:08:09,753 - INFO -   - Tensor shape: torch.Size([5632, 2048]), dtype: torch.bfloat16
2025-04-25 19:08:09,753 - INFO -   - Param shape: torch.Size([5632, 2048]), dtype: torch.float32
2025-04-25 19:08:09,955 - INFO -   - Copied. Param mean: 0.0000, std: 0.0168
2025-04-25 19:08:09,955 - INFO - Loading model.layers.7.mlp.down_proj.weight:
2025-04-25 19:08:09,956 - INFO -   - Tensor shape: torch.Size([2048, 5632]), dtype: torch.bfloat16
2025-04-25 19:08:09,956 - INFO -   - Param shape: torch.Size([2048, 5632]), dtype: torch.float32
2025-04-25 19:08:10,144 - INFO -   - Copied. Param mean: 0.0000, std: 0.0167
2025-04-25 19:08:10,144 - INFO - Loading model.layers.8.input_layernorm.weight:
2025-04-25 19:08:10,145 - INFO -   - Tensor shape: torch.Size([2048]), dtype: torch.bfloat16
2025-04-25 19:08:10,145 - INFO -   - Param shape: torch.Size([2048]), dtype: torch.float32
2025-04-25 19:08:10,145 - INFO -   - Copied. Param mean: 0.3188, std: 0.1083
2025-04-25 19:08:10,146 - INFO - Loading model.layers.8.post_attention_layernorm.weight:
2025-04-25 19:08:10,146 - INFO -   - Tensor shape: torch.Size([2048]), dtype: torch.bfloat16
2025-04-25 19:08:10,146 - INFO -   - Param shape: torch.Size([2048]), dtype: torch.float32
2025-04-25 19:08:10,146 - INFO -   - Copied. Param mean: 0.2645, std: 0.0304
2025-04-25 19:08:10,147 - INFO - Loading model.layers.8.self_attn.q_proj.weight:
2025-04-25 19:08:10,147 - INFO -   - Tensor shape: torch.Size([2048, 2048]), dtype: torch.bfloat16
2025-04-25 19:08:10,147 - INFO -   - Param shape: torch.Size([2048, 2048]), dtype: torch.float32
2025-04-25 19:08:10,221 - INFO -   - Copied. Param mean: -0.0000, std: 0.0273
2025-04-25 19:08:10,221 - INFO - Loading model.layers.8.self_attn.k_proj.weight:
2025-04-25 19:08:10,221 - INFO -   - Tensor shape: torch.Size([256, 2048]), dtype: torch.bfloat16
2025-04-25 19:08:10,222 - INFO -   - Param shape: torch.Size([256, 2048]), dtype: torch.float32
2025-04-25 19:08:10,240 - INFO -   - Copied. Param mean: -0.0000, std: 0.0466
2025-04-25 19:08:10,241 - INFO - Loading model.layers.8.self_attn.v_proj.weight:
2025-04-25 19:08:10,241 - INFO -   - Tensor shape: torch.Size([256, 2048]), dtype: torch.bfloat16
2025-04-25 19:08:10,241 - INFO -   - Param shape: torch.Size([256, 2048]), dtype: torch.float32
2025-04-25 19:08:10,265 - INFO -   - Copied. Param mean: -0.0000, std: 0.0121
2025-04-25 19:08:10,265 - INFO - Loading model.layers.8.self_attn.o_proj.weight:
2025-04-25 19:08:10,265 - INFO -   - Tensor shape: torch.Size([2048, 2048]), dtype: torch.bfloat16
2025-04-25 19:08:10,266 - INFO -   - Param shape: torch.Size([2048, 2048]), dtype: torch.float32
2025-04-25 19:08:10,343 - INFO -   - Copied. Param mean: -0.0000, std: 0.0145
2025-04-25 19:08:10,343 - INFO - Loading model.layers.8.mlp.gate_proj.weight:
2025-04-25 19:08:10,343 - INFO -   - Tensor shape: torch.Size([5632, 2048]), dtype: torch.bfloat16
2025-04-25 19:08:10,344 - INFO -   - Param shape: torch.Size([5632, 2048]), dtype: torch.float32
2025-04-25 19:08:10,561 - INFO -   - Copied. Param mean: 0.0001, std: 0.0202
2025-04-25 19:08:10,562 - INFO - Loading model.layers.8.mlp.up_proj.weight:
2025-04-25 19:08:10,562 - INFO -   - Tensor shape: torch.Size([5632, 2048]), dtype: torch.bfloat16
2025-04-25 19:08:10,562 - INFO -   - Param shape: torch.Size([5632, 2048]), dtype: torch.float32
2025-04-25 19:08:10,775 - INFO -   - Copied. Param mean: 0.0000, std: 0.0173
2025-04-25 19:08:10,776 - INFO - Loading model.layers.8.mlp.down_proj.weight:
2025-04-25 19:08:10,776 - INFO -   - Tensor shape: torch.Size([2048, 5632]), dtype: torch.bfloat16
2025-04-25 19:08:10,776 - INFO -   - Param shape: torch.Size([2048, 5632]), dtype: torch.float32
2025-04-25 19:08:10,979 - INFO -   - Copied. Param mean: 0.0000, std: 0.0172
2025-04-25 19:08:10,979 - INFO - Loading model.layers.9.input_layernorm.weight:
2025-04-25 19:08:10,979 - INFO -   - Tensor shape: torch.Size([2048]), dtype: torch.bfloat16
2025-04-25 19:08:10,980 - INFO -   - Param shape: torch.Size([2048]), dtype: torch.float32
2025-04-25 19:08:10,980 - INFO -   - Copied. Param mean: 0.3141, std: 0.0609
2025-04-25 19:08:10,981 - INFO - Loading model.layers.9.post_attention_layernorm.weight:
2025-04-25 19:08:10,981 - INFO -   - Tensor shape: torch.Size([2048]), dtype: torch.bfloat16
2025-04-25 19:08:10,981 - INFO -   - Param shape: torch.Size([2048]), dtype: torch.float32
2025-04-25 19:08:10,982 - INFO -   - Copied. Param mean: 0.2707, std: 0.0268
2025-04-25 19:08:10,982 - INFO - Loading model.layers.9.self_attn.q_proj.weight:
2025-04-25 19:08:10,982 - INFO -   - Tensor shape: torch.Size([2048, 2048]), dtype: torch.bfloat16
2025-04-25 19:08:10,982 - INFO -   - Param shape: torch.Size([2048, 2048]), dtype: torch.float32
2025-04-25 19:08:11,063 - INFO -   - Copied. Param mean: 0.0000, std: 0.0266
2025-04-25 19:08:11,063 - INFO - Loading model.layers.9.self_attn.k_proj.weight:
2025-04-25 19:08:11,063 - INFO -   - Tensor shape: torch.Size([256, 2048]), dtype: torch.bfloat16
2025-04-25 19:08:11,064 - INFO -   - Param shape: torch.Size([256, 2048]), dtype: torch.float32
2025-04-25 19:08:11,085 - INFO -   - Copied. Param mean: 0.0001, std: 0.0479
2025-04-25 19:08:11,085 - INFO - Loading model.layers.9.self_attn.v_proj.weight:
2025-04-25 19:08:11,086 - INFO -   - Tensor shape: torch.Size([256, 2048]), dtype: torch.bfloat16
2025-04-25 19:08:11,086 - INFO -   - Param shape: torch.Size([256, 2048]), dtype: torch.float32
2025-04-25 19:08:11,096 - INFO -   - Copied. Param mean: 0.0000, std: 0.0122
2025-04-25 19:08:11,097 - INFO - Loading model.layers.9.self_attn.o_proj.weight:
2025-04-25 19:08:11,097 - INFO -   - Tensor shape: torch.Size([2048, 2048]), dtype: torch.bfloat16
2025-04-25 19:08:11,097 - INFO -   - Param shape: torch.Size([2048, 2048]), dtype: torch.float32
2025-04-25 19:08:11,175 - INFO -   - Copied. Param mean: 0.0000, std: 0.0150
2025-04-25 19:08:11,176 - INFO - Loading model.layers.9.mlp.gate_proj.weight:
2025-04-25 19:08:11,176 - INFO -   - Tensor shape: torch.Size([5632, 2048]), dtype: torch.bfloat16
2025-04-25 19:08:11,176 - INFO -   - Param shape: torch.Size([5632, 2048]), dtype: torch.float32
2025-04-25 19:08:11,381 - INFO -   - Copied. Param mean: 0.0000, std: 0.0207
2025-04-25 19:08:11,382 - INFO - Loading model.layers.9.mlp.up_proj.weight:
2025-04-25 19:08:11,382 - INFO -   - Tensor shape: torch.Size([5632, 2048]), dtype: torch.bfloat16
2025-04-25 19:08:11,382 - INFO -   - Param shape: torch.Size([5632, 2048]), dtype: torch.float32
2025-04-25 19:08:11,587 - INFO -   - Copied. Param mean: 0.0000, std: 0.0171
2025-04-25 19:08:11,587 - INFO - Loading model.layers.9.mlp.down_proj.weight:
2025-04-25 19:08:11,587 - INFO -   - Tensor shape: torch.Size([2048, 5632]), dtype: torch.bfloat16
2025-04-25 19:08:11,588 - INFO -   - Param shape: torch.Size([2048, 5632]), dtype: torch.float32
2025-04-25 19:08:11,814 - INFO -   - Copied. Param mean: -0.0000, std: 0.0169
2025-04-25 19:08:11,815 - INFO - Loading model.layers.10.input_layernorm.weight:
2025-04-25 19:08:11,815 - INFO -   - Tensor shape: torch.Size([2048]), dtype: torch.bfloat16
2025-04-25 19:08:11,815 - INFO -   - Param shape: torch.Size([2048]), dtype: torch.float32
2025-04-25 19:08:11,816 - INFO -   - Copied. Param mean: 0.3328, std: 0.0563
2025-04-25 19:08:11,816 - INFO - Loading model.layers.10.post_attention_layernorm.weight:
2025-04-25 19:08:11,817 - INFO -   - Tensor shape: torch.Size([2048]), dtype: torch.bfloat16
2025-04-25 19:08:11,817 - INFO -   - Param shape: torch.Size([2048]), dtype: torch.float32
2025-04-25 19:08:11,817 - INFO -   - Copied. Param mean: 0.2796, std: 0.0302
2025-04-25 19:08:11,818 - INFO - Loading model.layers.10.self_attn.q_proj.weight:
2025-04-25 19:08:11,818 - INFO -   - Tensor shape: torch.Size([2048, 2048]), dtype: torch.bfloat16
2025-04-25 19:08:11,818 - INFO -   - Param shape: torch.Size([2048, 2048]), dtype: torch.float32
2025-04-25 19:08:11,898 - INFO -   - Copied. Param mean: 0.0000, std: 0.0268
2025-04-25 19:08:11,898 - INFO - Loading model.layers.10.self_attn.k_proj.weight:
2025-04-25 19:08:11,899 - INFO -   - Tensor shape: torch.Size([256, 2048]), dtype: torch.bfloat16
2025-04-25 19:08:11,899 - INFO -   - Param shape: torch.Size([256, 2048]), dtype: torch.float32
2025-04-25 19:08:11,920 - INFO -   - Copied. Param mean: -0.0000, std: 0.0493
2025-04-25 19:08:11,920 - INFO - Loading model.layers.10.self_attn.v_proj.weight:
2025-04-25 19:08:11,921 - INFO -   - Tensor shape: torch.Size([256, 2048]), dtype: torch.bfloat16
2025-04-25 19:08:11,921 - INFO -   - Param shape: torch.Size([256, 2048]), dtype: torch.float32
2025-04-25 19:08:11,935 - INFO -   - Copied. Param mean: -0.0000, std: 0.0123
2025-04-25 19:08:11,935 - INFO - Loading model.layers.10.self_attn.o_proj.weight:
2025-04-25 19:08:11,936 - INFO -   - Tensor shape: torch.Size([2048, 2048]), dtype: torch.bfloat16
2025-04-25 19:08:11,936 - INFO -   - Param shape: torch.Size([2048, 2048]), dtype: torch.float32
2025-04-25 19:08:12,011 - INFO -   - Copied. Param mean: 0.0000, std: 0.0149
2025-04-25 19:08:12,011 - INFO - Loading model.layers.10.mlp.gate_proj.weight:
2025-04-25 19:08:12,012 - INFO -   - Tensor shape: torch.Size([5632, 2048]), dtype: torch.bfloat16
2025-04-25 19:08:12,012 - INFO -   - Param shape: torch.Size([5632, 2048]), dtype: torch.float32
2025-04-25 19:08:12,244 - INFO -   - Copied. Param mean: 0.0000, std: 0.0204
2025-04-25 19:08:12,244 - INFO - Loading model.layers.10.mlp.up_proj.weight:
2025-04-25 19:08:12,245 - INFO -   - Tensor shape: torch.Size([5632, 2048]), dtype: torch.bfloat16
2025-04-25 19:08:12,245 - INFO -   - Param shape: torch.Size([5632, 2048]), dtype: torch.float32
2025-04-25 19:08:12,466 - INFO -   - Copied. Param mean: 0.0000, std: 0.0174
2025-04-25 19:08:12,466 - INFO - Loading model.layers.10.mlp.down_proj.weight:
2025-04-25 19:08:12,466 - INFO -   - Tensor shape: torch.Size([2048, 5632]), dtype: torch.bfloat16
2025-04-25 19:08:12,467 - INFO -   - Param shape: torch.Size([2048, 5632]), dtype: torch.float32
2025-04-25 19:08:12,699 - INFO -   - Copied. Param mean: 0.0000, std: 0.0173
2025-04-25 19:08:12,699 - INFO - Loading model.layers.11.input_layernorm.weight:
2025-04-25 19:08:12,699 - INFO -   - Tensor shape: torch.Size([2048]), dtype: torch.bfloat16
2025-04-25 19:08:12,700 - INFO -   - Param shape: torch.Size([2048]), dtype: torch.float32
2025-04-25 19:08:12,700 - INFO -   - Copied. Param mean: 0.3955, std: 0.0736
2025-04-25 19:08:12,700 - INFO - Loading model.layers.11.post_attention_layernorm.weight:
2025-04-25 19:08:12,701 - INFO -   - Tensor shape: torch.Size([2048]), dtype: torch.bfloat16
2025-04-25 19:08:12,701 - INFO -   - Param shape: torch.Size([2048]), dtype: torch.float32
2025-04-25 19:08:12,701 - INFO -   - Copied. Param mean: 0.2884, std: 0.0302
2025-04-25 19:08:12,702 - INFO - Loading model.layers.11.self_attn.q_proj.weight:
2025-04-25 19:08:12,702 - INFO -   - Tensor shape: torch.Size([2048, 2048]), dtype: torch.bfloat16
2025-04-25 19:08:12,702 - INFO -   - Param shape: torch.Size([2048, 2048]), dtype: torch.float32
2025-04-25 19:08:12,791 - INFO -   - Copied. Param mean: 0.0000, std: 0.0256
2025-04-25 19:08:12,791 - INFO - Loading model.layers.11.self_attn.k_proj.weight:
2025-04-25 19:08:12,792 - INFO -   - Tensor shape: torch.Size([256, 2048]), dtype: torch.bfloat16
2025-04-25 19:08:12,792 - INFO -   - Param shape: torch.Size([256, 2048]), dtype: torch.float32
2025-04-25 19:08:12,812 - INFO -   - Copied. Param mean: -0.0001, std: 0.0445
2025-04-25 19:08:12,812 - INFO - Loading model.layers.11.self_attn.v_proj.weight:
2025-04-25 19:08:12,812 - INFO -   - Tensor shape: torch.Size([256, 2048]), dtype: torch.bfloat16
2025-04-25 19:08:12,813 - INFO -   - Param shape: torch.Size([256, 2048]), dtype: torch.float32
2025-04-25 19:08:12,827 - INFO -   - Copied. Param mean: 0.0000, std: 0.0115
2025-04-25 19:08:12,827 - INFO - Loading model.layers.11.self_attn.o_proj.weight:
2025-04-25 19:08:12,828 - INFO -   - Tensor shape: torch.Size([2048, 2048]), dtype: torch.bfloat16
2025-04-25 19:08:12,828 - INFO -   - Param shape: torch.Size([2048, 2048]), dtype: torch.float32
2025-04-25 19:08:12,897 - INFO -   - Copied. Param mean: 0.0000, std: 0.0146
2025-04-25 19:08:12,898 - INFO - Loading model.layers.11.mlp.gate_proj.weight:
2025-04-25 19:08:12,898 - INFO -   - Tensor shape: torch.Size([5632, 2048]), dtype: torch.bfloat16
2025-04-25 19:08:12,898 - INFO -   - Param shape: torch.Size([5632, 2048]), dtype: torch.float32
2025-04-25 19:08:13,094 - INFO -   - Copied. Param mean: -0.0000, std: 0.0205
2025-04-25 19:08:13,094 - INFO - Loading model.layers.11.mlp.up_proj.weight:
2025-04-25 19:08:13,094 - INFO -   - Tensor shape: torch.Size([5632, 2048]), dtype: torch.bfloat16
2025-04-25 19:08:13,095 - INFO -   - Param shape: torch.Size([5632, 2048]), dtype: torch.float32
2025-04-25 19:08:13,313 - INFO -   - Copied. Param mean: -0.0000, std: 0.0174
2025-04-25 19:08:13,314 - INFO - Loading model.layers.11.mlp.down_proj.weight:
2025-04-25 19:08:13,314 - INFO -   - Tensor shape: torch.Size([2048, 5632]), dtype: torch.bfloat16
2025-04-25 19:08:13,314 - INFO -   - Param shape: torch.Size([2048, 5632]), dtype: torch.float32
2025-04-25 19:08:13,557 - INFO -   - Copied. Param mean: -0.0000, std: 0.0172
2025-04-25 19:08:13,558 - INFO - Loading model.layers.12.input_layernorm.weight:
2025-04-25 19:08:13,558 - INFO -   - Tensor shape: torch.Size([2048]), dtype: torch.bfloat16
2025-04-25 19:08:13,559 - INFO -   - Param shape: torch.Size([2048]), dtype: torch.float32
2025-04-25 19:08:13,559 - INFO -   - Copied. Param mean: 0.3438, std: 0.0674
2025-04-25 19:08:13,560 - INFO - Loading model.layers.12.post_attention_layernorm.weight:
2025-04-25 19:08:13,560 - INFO -   - Tensor shape: torch.Size([2048]), dtype: torch.bfloat16
2025-04-25 19:08:13,560 - INFO -   - Param shape: torch.Size([2048]), dtype: torch.float32
2025-04-25 19:08:13,561 - INFO -   - Copied. Param mean: 0.2991, std: 0.0256
2025-04-25 19:08:13,561 - INFO - Loading model.layers.12.self_attn.q_proj.weight:
2025-04-25 19:08:13,561 - INFO -   - Tensor shape: torch.Size([2048, 2048]), dtype: torch.bfloat16
2025-04-25 19:08:13,561 - INFO -   - Param shape: torch.Size([2048, 2048]), dtype: torch.float32
2025-04-25 19:08:13,650 - INFO -   - Copied. Param mean: -0.0000, std: 0.0259
2025-04-25 19:08:13,651 - INFO - Loading model.layers.12.self_attn.k_proj.weight:
2025-04-25 19:08:13,651 - INFO -   - Tensor shape: torch.Size([256, 2048]), dtype: torch.bfloat16
2025-04-25 19:08:13,651 - INFO -   - Param shape: torch.Size([256, 2048]), dtype: torch.float32
2025-04-25 19:08:13,672 - INFO -   - Copied. Param mean: -0.0001, std: 0.0462
2025-04-25 19:08:13,672 - INFO - Loading model.layers.12.self_attn.v_proj.weight:
2025-04-25 19:08:13,673 - INFO -   - Tensor shape: torch.Size([256, 2048]), dtype: torch.bfloat16
2025-04-25 19:08:13,673 - INFO -   - Param shape: torch.Size([256, 2048]), dtype: torch.float32
2025-04-25 19:08:13,702 - INFO -   - Copied. Param mean: -0.0001, std: 0.0144
2025-04-25 19:08:13,702 - INFO - Loading model.layers.12.self_attn.o_proj.weight:
2025-04-25 19:08:13,703 - INFO -   - Tensor shape: torch.Size([2048, 2048]), dtype: torch.bfloat16
2025-04-25 19:08:13,703 - INFO -   - Param shape: torch.Size([2048, 2048]), dtype: torch.float32
2025-04-25 19:08:13,777 - INFO -   - Copied. Param mean: -0.0000, std: 0.0157
2025-04-25 19:08:13,778 - INFO - Loading model.layers.12.mlp.gate_proj.weight:
2025-04-25 19:08:13,778 - INFO -   - Tensor shape: torch.Size([5632, 2048]), dtype: torch.bfloat16
2025-04-25 19:08:13,778 - INFO -   - Param shape: torch.Size([5632, 2048]), dtype: torch.float32
2025-04-25 19:08:14,010 - INFO -   - Copied. Param mean: -0.0000, std: 0.0212
2025-04-25 19:08:14,011 - INFO - Loading model.layers.12.mlp.up_proj.weight:
2025-04-25 19:08:14,011 - INFO -   - Tensor shape: torch.Size([5632, 2048]), dtype: torch.bfloat16
2025-04-25 19:08:14,011 - INFO -   - Param shape: torch.Size([5632, 2048]), dtype: torch.float32
2025-04-25 19:08:14,213 - INFO -   - Copied. Param mean: -0.0000, std: 0.0172
2025-04-25 19:08:14,213 - INFO - Loading model.layers.12.mlp.down_proj.weight:
2025-04-25 19:08:14,214 - INFO -   - Tensor shape: torch.Size([2048, 5632]), dtype: torch.bfloat16
2025-04-25 19:08:14,214 - INFO -   - Param shape: torch.Size([2048, 5632]), dtype: torch.float32
2025-04-25 19:08:14,424 - INFO -   - Copied. Param mean: -0.0000, std: 0.0170
2025-04-25 19:08:14,424 - INFO - Loading model.layers.13.input_layernorm.weight:
2025-04-25 19:08:14,425 - INFO -   - Tensor shape: torch.Size([2048]), dtype: torch.bfloat16
2025-04-25 19:08:14,425 - INFO -   - Param shape: torch.Size([2048]), dtype: torch.float32
2025-04-25 19:08:14,425 - INFO -   - Copied. Param mean: 0.3773, std: 0.0761
2025-04-25 19:08:14,426 - INFO - Loading model.layers.13.post_attention_layernorm.weight:
2025-04-25 19:08:14,426 - INFO -   - Tensor shape: torch.Size([2048]), dtype: torch.bfloat16
2025-04-25 19:08:14,426 - INFO -   - Param shape: torch.Size([2048]), dtype: torch.float32
2025-04-25 19:08:14,427 - INFO -   - Copied. Param mean: 0.3128, std: 0.0242
2025-04-25 19:08:14,427 - INFO - Loading model.layers.13.self_attn.q_proj.weight:
2025-04-25 19:08:14,427 - INFO -   - Tensor shape: torch.Size([2048, 2048]), dtype: torch.bfloat16
2025-04-25 19:08:14,427 - INFO -   - Param shape: torch.Size([2048, 2048]), dtype: torch.float32
2025-04-25 19:08:14,509 - INFO -   - Copied. Param mean: 0.0000, std: 0.0254
2025-04-25 19:08:14,509 - INFO - Loading model.layers.13.self_attn.k_proj.weight:
2025-04-25 19:08:14,509 - INFO -   - Tensor shape: torch.Size([256, 2048]), dtype: torch.bfloat16
2025-04-25 19:08:14,510 - INFO -   - Param shape: torch.Size([256, 2048]), dtype: torch.float32
2025-04-25 19:08:14,530 - INFO -   - Copied. Param mean: -0.0000, std: 0.0469
2025-04-25 19:08:14,531 - INFO - Loading model.layers.13.self_attn.v_proj.weight:
2025-04-25 19:08:14,531 - INFO -   - Tensor shape: torch.Size([256, 2048]), dtype: torch.bfloat16
2025-04-25 19:08:14,531 - INFO -   - Param shape: torch.Size([256, 2048]), dtype: torch.float32
2025-04-25 19:08:14,546 - INFO -   - Copied. Param mean: -0.0000, std: 0.0123
2025-04-25 19:08:14,546 - INFO - Loading model.layers.13.self_attn.o_proj.weight:
2025-04-25 19:08:14,546 - INFO -   - Tensor shape: torch.Size([2048, 2048]), dtype: torch.bfloat16
2025-04-25 19:08:14,547 - INFO -   - Param shape: torch.Size([2048, 2048]), dtype: torch.float32
2025-04-25 19:08:14,631 - INFO -   - Copied. Param mean: -0.0000, std: 0.0151
2025-04-25 19:08:14,631 - INFO - Loading model.layers.13.mlp.gate_proj.weight:
2025-04-25 19:08:14,631 - INFO -   - Tensor shape: torch.Size([5632, 2048]), dtype: torch.bfloat16
2025-04-25 19:08:14,632 - INFO -   - Param shape: torch.Size([5632, 2048]), dtype: torch.float32
2025-04-25 19:08:14,857 - INFO -   - Copied. Param mean: -0.0000, std: 0.0211
2025-04-25 19:08:14,858 - INFO - Loading model.layers.13.mlp.up_proj.weight:
2025-04-25 19:08:14,858 - INFO -   - Tensor shape: torch.Size([5632, 2048]), dtype: torch.bfloat16
2025-04-25 19:08:14,858 - INFO -   - Param shape: torch.Size([5632, 2048]), dtype: torch.float32
2025-04-25 19:08:15,080 - INFO -   - Copied. Param mean: -0.0000, std: 0.0174
2025-04-25 19:08:15,080 - INFO - Loading model.layers.13.mlp.down_proj.weight:
2025-04-25 19:08:15,080 - INFO -   - Tensor shape: torch.Size([2048, 5632]), dtype: torch.bfloat16
2025-04-25 19:08:15,081 - INFO -   - Param shape: torch.Size([2048, 5632]), dtype: torch.float32
2025-04-25 19:08:15,298 - INFO -   - Copied. Param mean: 0.0000, std: 0.0172
2025-04-25 19:08:15,299 - INFO - Loading model.layers.14.input_layernorm.weight:
2025-04-25 19:08:15,299 - INFO -   - Tensor shape: torch.Size([2048]), dtype: torch.bfloat16
2025-04-25 19:08:15,300 - INFO -   - Param shape: torch.Size([2048]), dtype: torch.float32
2025-04-25 19:08:15,300 - INFO -   - Copied. Param mean: 0.3614, std: 0.0651
2025-04-25 19:08:15,300 - INFO - Loading model.layers.14.post_attention_layernorm.weight:
2025-04-25 19:08:15,300 - INFO -   - Tensor shape: torch.Size([2048]), dtype: torch.bfloat16
2025-04-25 19:08:15,301 - INFO -   - Param shape: torch.Size([2048]), dtype: torch.float32
2025-04-25 19:08:15,301 - INFO -   - Copied. Param mean: 0.3289, std: 0.0258
2025-04-25 19:08:15,301 - INFO - Loading model.layers.14.self_attn.q_proj.weight:
2025-04-25 19:08:15,302 - INFO -   - Tensor shape: torch.Size([2048, 2048]), dtype: torch.bfloat16
2025-04-25 19:08:15,302 - INFO -   - Param shape: torch.Size([2048, 2048]), dtype: torch.float32
2025-04-25 19:08:15,379 - INFO -   - Copied. Param mean: -0.0000, std: 0.0256
2025-04-25 19:08:15,380 - INFO - Loading model.layers.14.self_attn.k_proj.weight:
2025-04-25 19:08:15,380 - INFO -   - Tensor shape: torch.Size([256, 2048]), dtype: torch.bfloat16
2025-04-25 19:08:15,380 - INFO -   - Param shape: torch.Size([256, 2048]), dtype: torch.float32
2025-04-25 19:08:15,400 - INFO -   - Copied. Param mean: -0.0000, std: 0.0482
2025-04-25 19:08:15,400 - INFO - Loading model.layers.14.self_attn.v_proj.weight:
2025-04-25 19:08:15,400 - INFO -   - Tensor shape: torch.Size([256, 2048]), dtype: torch.bfloat16
2025-04-25 19:08:15,401 - INFO -   - Param shape: torch.Size([256, 2048]), dtype: torch.float32
2025-04-25 19:08:15,420 - INFO -   - Copied. Param mean: 0.0000, std: 0.0134
2025-04-25 19:08:15,420 - INFO - Loading model.layers.14.self_attn.o_proj.weight:
2025-04-25 19:08:15,421 - INFO -   - Tensor shape: torch.Size([2048, 2048]), dtype: torch.bfloat16
2025-04-25 19:08:15,421 - INFO -   - Param shape: torch.Size([2048, 2048]), dtype: torch.float32
2025-04-25 19:08:15,498 - INFO -   - Copied. Param mean: -0.0000, std: 0.0155
2025-04-25 19:08:15,498 - INFO - Loading model.layers.14.mlp.gate_proj.weight:
2025-04-25 19:08:15,499 - INFO -   - Tensor shape: torch.Size([5632, 2048]), dtype: torch.bfloat16
2025-04-25 19:08:15,499 - INFO -   - Param shape: torch.Size([5632, 2048]), dtype: torch.float32
2025-04-25 19:08:15,709 - INFO -   - Copied. Param mean: -0.0001, std: 0.0211
2025-04-25 19:08:15,710 - INFO - Loading model.layers.14.mlp.up_proj.weight:
2025-04-25 19:08:15,710 - INFO -   - Tensor shape: torch.Size([5632, 2048]), dtype: torch.bfloat16
2025-04-25 19:08:15,710 - INFO -   - Param shape: torch.Size([5632, 2048]), dtype: torch.float32
2025-04-25 19:08:15,939 - INFO -   - Copied. Param mean: 0.0000, std: 0.0179
2025-04-25 19:08:15,940 - INFO - Loading model.layers.14.mlp.down_proj.weight:
2025-04-25 19:08:15,940 - INFO -   - Tensor shape: torch.Size([2048, 5632]), dtype: torch.bfloat16
2025-04-25 19:08:15,940 - INFO -   - Param shape: torch.Size([2048, 5632]), dtype: torch.float32
2025-04-25 19:08:16,182 - INFO -   - Copied. Param mean: 0.0000, std: 0.0176
2025-04-25 19:08:16,182 - INFO - Loading model.layers.15.input_layernorm.weight:
2025-04-25 19:08:16,182 - INFO -   - Tensor shape: torch.Size([2048]), dtype: torch.bfloat16
2025-04-25 19:08:16,183 - INFO -   - Param shape: torch.Size([2048]), dtype: torch.float32
2025-04-25 19:08:16,183 - INFO -   - Copied. Param mean: 0.4188, std: 0.0651
2025-04-25 19:08:16,183 - INFO - Loading model.layers.15.post_attention_layernorm.weight:
2025-04-25 19:08:16,183 - INFO -   - Tensor shape: torch.Size([2048]), dtype: torch.bfloat16
2025-04-25 19:08:16,184 - INFO -   - Param shape: torch.Size([2048]), dtype: torch.float32
2025-04-25 19:08:16,184 - INFO -   - Copied. Param mean: 0.3524, std: 0.0248
2025-04-25 19:08:16,184 - INFO - Loading model.layers.15.self_attn.q_proj.weight:
2025-04-25 19:08:16,184 - INFO -   - Tensor shape: torch.Size([2048, 2048]), dtype: torch.bfloat16
2025-04-25 19:08:16,185 - INFO -   - Param shape: torch.Size([2048, 2048]), dtype: torch.float32
2025-04-25 19:08:16,268 - INFO -   - Copied. Param mean: -0.0000, std: 0.0260
2025-04-25 19:08:16,269 - INFO - Loading model.layers.15.self_attn.k_proj.weight:
2025-04-25 19:08:16,269 - INFO -   - Tensor shape: torch.Size([256, 2048]), dtype: torch.bfloat16
2025-04-25 19:08:16,269 - INFO -   - Param shape: torch.Size([256, 2048]), dtype: torch.float32
2025-04-25 19:08:16,289 - INFO -   - Copied. Param mean: 0.0001, std: 0.0428
2025-04-25 19:08:16,290 - INFO - Loading model.layers.15.self_attn.v_proj.weight:
2025-04-25 19:08:16,290 - INFO -   - Tensor shape: torch.Size([256, 2048]), dtype: torch.bfloat16
2025-04-25 19:08:16,290 - INFO -   - Param shape: torch.Size([256, 2048]), dtype: torch.float32
2025-04-25 19:08:16,311 - INFO -   - Copied. Param mean: -0.0000, std: 0.0137
2025-04-25 19:08:16,311 - INFO - Loading model.layers.15.self_attn.o_proj.weight:
2025-04-25 19:08:16,311 - INFO -   - Tensor shape: torch.Size([2048, 2048]), dtype: torch.bfloat16
2025-04-25 19:08:16,311 - INFO -   - Param shape: torch.Size([2048, 2048]), dtype: torch.float32
2025-04-25 19:08:16,394 - INFO -   - Copied. Param mean: 0.0000, std: 0.0159
2025-04-25 19:08:16,395 - INFO - Loading model.layers.15.mlp.gate_proj.weight:
2025-04-25 19:08:16,395 - INFO -   - Tensor shape: torch.Size([5632, 2048]), dtype: torch.bfloat16
2025-04-25 19:08:16,396 - INFO -   - Param shape: torch.Size([5632, 2048]), dtype: torch.float32
2025-04-25 19:08:16,623 - INFO -   - Copied. Param mean: -0.0001, std: 0.0211
2025-04-25 19:08:16,624 - INFO - Loading model.layers.15.mlp.up_proj.weight:
2025-04-25 19:08:16,624 - INFO -   - Tensor shape: torch.Size([5632, 2048]), dtype: torch.bfloat16
2025-04-25 19:08:16,624 - INFO -   - Param shape: torch.Size([5632, 2048]), dtype: torch.float32
2025-04-25 19:08:16,854 - INFO -   - Copied. Param mean: -0.0000, std: 0.0180
2025-04-25 19:08:16,855 - INFO - Loading model.layers.15.mlp.down_proj.weight:
2025-04-25 19:08:16,855 - INFO -   - Tensor shape: torch.Size([2048, 5632]), dtype: torch.bfloat16
2025-04-25 19:08:16,855 - INFO -   - Param shape: torch.Size([2048, 5632]), dtype: torch.float32
2025-04-25 19:08:17,081 - INFO -   - Copied. Param mean: 0.0000, std: 0.0177
2025-04-25 19:08:17,081 - INFO - Loading model.layers.16.input_layernorm.weight:
2025-04-25 19:08:17,081 - INFO -   - Tensor shape: torch.Size([2048]), dtype: torch.bfloat16
2025-04-25 19:08:17,082 - INFO -   - Param shape: torch.Size([2048]), dtype: torch.float32
2025-04-25 19:08:17,082 - INFO -   - Copied. Param mean: 0.4019, std: 0.0667
2025-04-25 19:08:17,082 - INFO - Loading model.layers.16.post_attention_layernorm.weight:
2025-04-25 19:08:17,083 - INFO -   - Tensor shape: torch.Size([2048]), dtype: torch.bfloat16
2025-04-25 19:08:17,083 - INFO -   - Param shape: torch.Size([2048]), dtype: torch.float32
2025-04-25 19:08:17,083 - INFO -   - Copied. Param mean: 0.3908, std: 0.0267
2025-04-25 19:08:17,084 - INFO - Loading model.layers.16.self_attn.q_proj.weight:
2025-04-25 19:08:17,084 - INFO -   - Tensor shape: torch.Size([2048, 2048]), dtype: torch.bfloat16
2025-04-25 19:08:17,084 - INFO -   - Param shape: torch.Size([2048, 2048]), dtype: torch.float32
2025-04-25 19:08:17,155 - INFO -   - Copied. Param mean: -0.0000, std: 0.0265
2025-04-25 19:08:17,156 - INFO - Loading model.layers.16.self_attn.k_proj.weight:
2025-04-25 19:08:17,156 - INFO -   - Tensor shape: torch.Size([256, 2048]), dtype: torch.bfloat16
2025-04-25 19:08:17,156 - INFO -   - Param shape: torch.Size([256, 2048]), dtype: torch.float32
2025-04-25 19:08:17,166 - INFO -   - Copied. Param mean: 0.0000, std: 0.0440
2025-04-25 19:08:17,166 - INFO - Loading model.layers.16.self_attn.v_proj.weight:
2025-04-25 19:08:17,166 - INFO -   - Tensor shape: torch.Size([256, 2048]), dtype: torch.bfloat16
2025-04-25 19:08:17,166 - INFO -   - Param shape: torch.Size([256, 2048]), dtype: torch.float32
2025-04-25 19:08:17,178 - INFO -   - Copied. Param mean: -0.0000, std: 0.0151
2025-04-25 19:08:17,178 - INFO - Loading model.layers.16.self_attn.o_proj.weight:
2025-04-25 19:08:17,178 - INFO -   - Tensor shape: torch.Size([2048, 2048]), dtype: torch.bfloat16
2025-04-25 19:08:17,179 - INFO -   - Param shape: torch.Size([2048, 2048]), dtype: torch.float32
2025-04-25 19:08:17,261 - INFO -   - Copied. Param mean: -0.0000, std: 0.0158
2025-04-25 19:08:17,262 - INFO - Loading model.layers.16.mlp.gate_proj.weight:
2025-04-25 19:08:17,262 - INFO -   - Tensor shape: torch.Size([5632, 2048]), dtype: torch.bfloat16
2025-04-25 19:08:17,262 - INFO -   - Param shape: torch.Size([5632, 2048]), dtype: torch.float32
2025-04-25 19:08:17,484 - INFO -   - Copied. Param mean: -0.0001, std: 0.0216
2025-04-25 19:08:17,484 - INFO - Loading model.layers.16.mlp.up_proj.weight:
2025-04-25 19:08:17,485 - INFO -   - Tensor shape: torch.Size([5632, 2048]), dtype: torch.bfloat16
2025-04-25 19:08:17,485 - INFO -   - Param shape: torch.Size([5632, 2048]), dtype: torch.float32
2025-04-25 19:08:17,697 - INFO -   - Copied. Param mean: 0.0000, std: 0.0180
2025-04-25 19:08:17,697 - INFO - Loading model.layers.16.mlp.down_proj.weight:
2025-04-25 19:08:17,697 - INFO -   - Tensor shape: torch.Size([2048, 5632]), dtype: torch.bfloat16
2025-04-25 19:08:17,698 - INFO -   - Param shape: torch.Size([2048, 5632]), dtype: torch.float32
2025-04-25 19:08:17,915 - INFO -   - Copied. Param mean: -0.0000, std: 0.0176
2025-04-25 19:08:17,916 - INFO - Loading model.layers.17.input_layernorm.weight:
2025-04-25 19:08:17,916 - INFO -   - Tensor shape: torch.Size([2048]), dtype: torch.bfloat16
2025-04-25 19:08:17,916 - INFO -   - Param shape: torch.Size([2048]), dtype: torch.float32
2025-04-25 19:08:17,917 - INFO -   - Copied. Param mean: 0.4315, std: 0.0760
2025-04-25 19:08:17,917 - INFO - Loading model.layers.17.post_attention_layernorm.weight:
2025-04-25 19:08:17,917 - INFO -   - Tensor shape: torch.Size([2048]), dtype: torch.bfloat16
2025-04-25 19:08:17,918 - INFO -   - Param shape: torch.Size([2048]), dtype: torch.float32
2025-04-25 19:08:17,918 - INFO -   - Copied. Param mean: 0.4231, std: 0.0308
2025-04-25 19:08:17,918 - INFO - Loading model.layers.17.self_attn.q_proj.weight:
2025-04-25 19:08:17,918 - INFO -   - Tensor shape: torch.Size([2048, 2048]), dtype: torch.bfloat16
2025-04-25 19:08:17,918 - INFO -   - Param shape: torch.Size([2048, 2048]), dtype: torch.float32
2025-04-25 19:08:18,008 - INFO -   - Copied. Param mean: 0.0000, std: 0.0243
2025-04-25 19:08:18,009 - INFO - Loading model.layers.17.self_attn.k_proj.weight:
2025-04-25 19:08:18,009 - INFO -   - Tensor shape: torch.Size([256, 2048]), dtype: torch.bfloat16
2025-04-25 19:08:18,009 - INFO -   - Param shape: torch.Size([256, 2048]), dtype: torch.float32
2025-04-25 19:08:18,025 - INFO -   - Copied. Param mean: 0.0000, std: 0.0404
2025-04-25 19:08:18,025 - INFO - Loading model.layers.17.self_attn.v_proj.weight:
2025-04-25 19:08:18,025 - INFO -   - Tensor shape: torch.Size([256, 2048]), dtype: torch.bfloat16
2025-04-25 19:08:18,026 - INFO -   - Param shape: torch.Size([256, 2048]), dtype: torch.float32
2025-04-25 19:08:18,048 - INFO -   - Copied. Param mean: -0.0000, std: 0.0188
2025-04-25 19:08:18,048 - INFO - Loading model.layers.17.self_attn.o_proj.weight:
2025-04-25 19:08:18,048 - INFO -   - Tensor shape: torch.Size([2048, 2048]), dtype: torch.bfloat16
2025-04-25 19:08:18,048 - INFO -   - Param shape: torch.Size([2048, 2048]), dtype: torch.float32
2025-04-25 19:08:18,131 - INFO -   - Copied. Param mean: -0.0000, std: 0.0171
2025-04-25 19:08:18,132 - INFO - Loading model.layers.17.mlp.gate_proj.weight:
2025-04-25 19:08:18,132 - INFO -   - Tensor shape: torch.Size([5632, 2048]), dtype: torch.bfloat16
2025-04-25 19:08:18,132 - INFO -   - Param shape: torch.Size([5632, 2048]), dtype: torch.float32
2025-04-25 19:08:18,343 - INFO -   - Copied. Param mean: -0.0001, std: 0.0217
2025-04-25 19:08:18,343 - INFO - Loading model.layers.17.mlp.up_proj.weight:
2025-04-25 19:08:18,344 - INFO -   - Tensor shape: torch.Size([5632, 2048]), dtype: torch.bfloat16
2025-04-25 19:08:18,344 - INFO -   - Param shape: torch.Size([5632, 2048]), dtype: torch.float32
2025-04-25 19:08:18,566 - INFO -   - Copied. Param mean: -0.0000, std: 0.0183
2025-04-25 19:08:18,567 - INFO - Loading model.layers.17.mlp.down_proj.weight:
2025-04-25 19:08:18,567 - INFO -   - Tensor shape: torch.Size([2048, 5632]), dtype: torch.bfloat16
2025-04-25 19:08:18,567 - INFO -   - Param shape: torch.Size([2048, 5632]), dtype: torch.float32
2025-04-25 19:08:18,758 - INFO -   - Copied. Param mean: -0.0000, std: 0.0180
2025-04-25 19:08:18,758 - INFO - Loading model.layers.18.input_layernorm.weight:
2025-04-25 19:08:18,759 - INFO -   - Tensor shape: torch.Size([2048]), dtype: torch.bfloat16
2025-04-25 19:08:18,759 - INFO -   - Param shape: torch.Size([2048]), dtype: torch.float32
2025-04-25 19:08:18,759 - INFO -   - Copied. Param mean: 0.4387, std: 0.0815
2025-04-25 19:08:18,759 - INFO - Loading model.layers.18.post_attention_layernorm.weight:
2025-04-25 19:08:18,759 - INFO -   - Tensor shape: torch.Size([2048]), dtype: torch.bfloat16
2025-04-25 19:08:18,760 - INFO -   - Param shape: torch.Size([2048]), dtype: torch.float32
2025-04-25 19:08:18,760 - INFO -   - Copied. Param mean: 0.4623, std: 0.0351
2025-04-25 19:08:18,760 - INFO - Loading model.layers.18.self_attn.q_proj.weight:
2025-04-25 19:08:18,760 - INFO -   - Tensor shape: torch.Size([2048, 2048]), dtype: torch.bfloat16
2025-04-25 19:08:18,760 - INFO -   - Param shape: torch.Size([2048, 2048]), dtype: torch.float32
2025-04-25 19:08:18,833 - INFO -   - Copied. Param mean: 0.0000, std: 0.0251
2025-04-25 19:08:18,834 - INFO - Loading model.layers.18.self_attn.k_proj.weight:
2025-04-25 19:08:18,834 - INFO -   - Tensor shape: torch.Size([256, 2048]), dtype: torch.bfloat16
2025-04-25 19:08:18,834 - INFO -   - Param shape: torch.Size([256, 2048]), dtype: torch.float32
2025-04-25 19:08:18,853 - INFO -   - Copied. Param mean: -0.0000, std: 0.0403
2025-04-25 19:08:18,854 - INFO - Loading model.layers.18.self_attn.v_proj.weight:
2025-04-25 19:08:18,854 - INFO -   - Tensor shape: torch.Size([256, 2048]), dtype: torch.bfloat16
2025-04-25 19:08:18,854 - INFO -   - Param shape: torch.Size([256, 2048]), dtype: torch.float32
2025-04-25 19:08:18,874 - INFO -   - Copied. Param mean: -0.0000, std: 0.0196
2025-04-25 19:08:18,874 - INFO - Loading model.layers.18.self_attn.o_proj.weight:
2025-04-25 19:08:18,874 - INFO -   - Tensor shape: torch.Size([2048, 2048]), dtype: torch.bfloat16
2025-04-25 19:08:18,874 - INFO -   - Param shape: torch.Size([2048, 2048]), dtype: torch.float32
2025-04-25 19:08:18,940 - INFO -   - Copied. Param mean: 0.0000, std: 0.0175
2025-04-25 19:08:18,940 - INFO - Loading model.layers.18.mlp.gate_proj.weight:
2025-04-25 19:08:18,940 - INFO -   - Tensor shape: torch.Size([5632, 2048]), dtype: torch.bfloat16
2025-04-25 19:08:18,940 - INFO -   - Param shape: torch.Size([5632, 2048]), dtype: torch.float32
2025-04-25 19:08:19,131 - INFO -   - Copied. Param mean: -0.0001, std: 0.0218
2025-04-25 19:08:19,131 - INFO - Loading model.layers.18.mlp.up_proj.weight:
2025-04-25 19:08:19,132 - INFO -   - Tensor shape: torch.Size([5632, 2048]), dtype: torch.bfloat16
2025-04-25 19:08:19,132 - INFO -   - Param shape: torch.Size([5632, 2048]), dtype: torch.float32
2025-04-25 19:08:19,325 - INFO -   - Copied. Param mean: 0.0000, std: 0.0186
2025-04-25 19:08:19,325 - INFO - Loading model.layers.18.mlp.down_proj.weight:
2025-04-25 19:08:19,325 - INFO -   - Tensor shape: torch.Size([2048, 5632]), dtype: torch.bfloat16
2025-04-25 19:08:19,326 - INFO -   - Param shape: torch.Size([2048, 5632]), dtype: torch.float32
2025-04-25 19:08:19,516 - INFO -   - Copied. Param mean: -0.0000, std: 0.0182
2025-04-25 19:08:19,517 - INFO - Loading model.layers.19.input_layernorm.weight:
2025-04-25 19:08:19,517 - INFO -   - Tensor shape: torch.Size([2048]), dtype: torch.bfloat16
2025-04-25 19:08:19,517 - INFO -   - Param shape: torch.Size([2048]), dtype: torch.float32
2025-04-25 19:08:19,518 - INFO -   - Copied. Param mean: 0.4350, std: 0.0937
2025-04-25 19:08:19,518 - INFO - Loading model.layers.19.post_attention_layernorm.weight:
2025-04-25 19:08:19,518 - INFO -   - Tensor shape: torch.Size([2048]), dtype: torch.bfloat16
2025-04-25 19:08:19,518 - INFO -   - Param shape: torch.Size([2048]), dtype: torch.float32
2025-04-25 19:08:19,518 - INFO -   - Copied. Param mean: 0.4969, std: 0.0362
2025-04-25 19:08:19,519 - INFO - Loading model.layers.19.self_attn.q_proj.weight:
2025-04-25 19:08:19,519 - INFO -   - Tensor shape: torch.Size([2048, 2048]), dtype: torch.bfloat16
2025-04-25 19:08:19,519 - INFO -   - Param shape: torch.Size([2048, 2048]), dtype: torch.float32
2025-04-25 19:08:19,585 - INFO -   - Copied. Param mean: -0.0000, std: 0.0242
2025-04-25 19:08:19,585 - INFO - Loading model.layers.19.self_attn.k_proj.weight:
2025-04-25 19:08:19,585 - INFO -   - Tensor shape: torch.Size([256, 2048]), dtype: torch.bfloat16
2025-04-25 19:08:19,586 - INFO -   - Param shape: torch.Size([256, 2048]), dtype: torch.float32
2025-04-25 19:08:19,594 - INFO -   - Copied. Param mean: 0.0000, std: 0.0386
2025-04-25 19:08:19,595 - INFO - Loading model.layers.19.self_attn.v_proj.weight:
2025-04-25 19:08:19,595 - INFO -   - Tensor shape: torch.Size([256, 2048]), dtype: torch.bfloat16
2025-04-25 19:08:19,595 - INFO -   - Param shape: torch.Size([256, 2048]), dtype: torch.float32
2025-04-25 19:08:19,604 - INFO -   - Copied. Param mean: 0.0000, std: 0.0231
2025-04-25 19:08:19,605 - INFO - Loading model.layers.19.self_attn.o_proj.weight:
2025-04-25 19:08:19,605 - INFO -   - Tensor shape: torch.Size([2048, 2048]), dtype: torch.bfloat16
2025-04-25 19:08:19,605 - INFO -   - Param shape: torch.Size([2048, 2048]), dtype: torch.float32
2025-04-25 19:08:19,670 - INFO -   - Copied. Param mean: -0.0000, std: 0.0184
2025-04-25 19:08:19,671 - INFO - Loading model.layers.19.mlp.gate_proj.weight:
2025-04-25 19:08:19,671 - INFO -   - Tensor shape: torch.Size([5632, 2048]), dtype: torch.bfloat16
2025-04-25 19:08:19,671 - INFO -   - Param shape: torch.Size([5632, 2048]), dtype: torch.float32
2025-04-25 19:08:19,861 - INFO -   - Copied. Param mean: -0.0001, std: 0.0218
2025-04-25 19:08:19,861 - INFO - Loading model.layers.19.mlp.up_proj.weight:
2025-04-25 19:08:19,862 - INFO -   - Tensor shape: torch.Size([5632, 2048]), dtype: torch.bfloat16
2025-04-25 19:08:19,862 - INFO -   - Param shape: torch.Size([5632, 2048]), dtype: torch.float32
2025-04-25 19:08:20,088 - INFO -   - Copied. Param mean: -0.0000, std: 0.0190
2025-04-25 19:08:20,088 - INFO - Loading model.layers.19.mlp.down_proj.weight:
2025-04-25 19:08:20,089 - INFO -   - Tensor shape: torch.Size([2048, 5632]), dtype: torch.bfloat16
2025-04-25 19:08:20,089 - INFO -   - Param shape: torch.Size([2048, 5632]), dtype: torch.float32
2025-04-25 19:08:20,301 - INFO -   - Copied. Param mean: -0.0000, std: 0.0186
2025-04-25 19:08:20,301 - INFO - Loading model.layers.20.input_layernorm.weight:
2025-04-25 19:08:20,302 - INFO -   - Tensor shape: torch.Size([2048]), dtype: torch.bfloat16
2025-04-25 19:08:20,302 - INFO -   - Param shape: torch.Size([2048]), dtype: torch.float32
2025-04-25 19:08:20,302 - INFO -   - Copied. Param mean: 0.4330, std: 0.0860
2025-04-25 19:08:20,302 - INFO - Loading model.layers.20.post_attention_layernorm.weight:
2025-04-25 19:08:20,302 - INFO -   - Tensor shape: torch.Size([2048]), dtype: torch.bfloat16
2025-04-25 19:08:20,303 - INFO -   - Param shape: torch.Size([2048]), dtype: torch.float32
2025-04-25 19:08:20,303 - INFO -   - Copied. Param mean: 0.5282, std: 0.0366
2025-04-25 19:08:20,303 - INFO - Loading model.layers.20.self_attn.q_proj.weight:
2025-04-25 19:08:20,303 - INFO -   - Tensor shape: torch.Size([2048, 2048]), dtype: torch.bfloat16
2025-04-25 19:08:20,304 - INFO -   - Param shape: torch.Size([2048, 2048]), dtype: torch.float32
2025-04-25 19:08:20,379 - INFO -   - Copied. Param mean: 0.0000, std: 0.0247
2025-04-25 19:08:20,380 - INFO - Loading model.layers.20.self_attn.k_proj.weight:
2025-04-25 19:08:20,380 - INFO -   - Tensor shape: torch.Size([256, 2048]), dtype: torch.bfloat16
2025-04-25 19:08:20,380 - INFO -   - Param shape: torch.Size([256, 2048]), dtype: torch.float32
2025-04-25 19:08:20,407 - INFO -   - Copied. Param mean: 0.0001, std: 0.0398
2025-04-25 19:08:20,408 - INFO - Loading model.layers.20.self_attn.v_proj.weight:
2025-04-25 19:08:20,408 - INFO -   - Tensor shape: torch.Size([256, 2048]), dtype: torch.bfloat16
2025-04-25 19:08:20,408 - INFO -   - Param shape: torch.Size([256, 2048]), dtype: torch.float32
2025-04-25 19:08:20,430 - INFO -   - Copied. Param mean: 0.0000, std: 0.0235
2025-04-25 19:08:20,431 - INFO - Loading model.layers.20.self_attn.o_proj.weight:
2025-04-25 19:08:20,431 - INFO -   - Tensor shape: torch.Size([2048, 2048]), dtype: torch.bfloat16
2025-04-25 19:08:20,431 - INFO -   - Param shape: torch.Size([2048, 2048]), dtype: torch.float32
2025-04-25 19:08:20,501 - INFO -   - Copied. Param mean: 0.0000, std: 0.0184
2025-04-25 19:08:20,501 - INFO - Loading model.layers.20.mlp.gate_proj.weight:
2025-04-25 19:08:20,502 - INFO -   - Tensor shape: torch.Size([5632, 2048]), dtype: torch.bfloat16
2025-04-25 19:08:20,502 - INFO -   - Param shape: torch.Size([5632, 2048]), dtype: torch.float32
2025-04-25 19:08:20,786 - INFO -   - Copied. Param mean: -0.0000, std: 0.0219
2025-04-25 19:08:20,787 - INFO - Loading model.layers.20.mlp.up_proj.weight:
2025-04-25 19:08:20,787 - INFO -   - Tensor shape: torch.Size([5632, 2048]), dtype: torch.bfloat16
2025-04-25 19:08:20,787 - INFO -   - Param shape: torch.Size([5632, 2048]), dtype: torch.float32
2025-04-25 19:08:21,002 - INFO -   - Copied. Param mean: -0.0000, std: 0.0194
2025-04-25 19:08:21,002 - INFO - Loading model.layers.20.mlp.down_proj.weight:
2025-04-25 19:08:21,003 - INFO -   - Tensor shape: torch.Size([2048, 5632]), dtype: torch.bfloat16
2025-04-25 19:08:21,003 - INFO -   - Param shape: torch.Size([2048, 5632]), dtype: torch.float32
2025-04-25 19:08:21,198 - INFO -   - Copied. Param mean: 0.0000, std: 0.0190
2025-04-25 19:08:21,199 - INFO - Loading model.layers.21.input_layernorm.weight:
2025-04-25 19:08:21,199 - INFO -   - Tensor shape: torch.Size([2048]), dtype: torch.bfloat16
2025-04-25 19:08:21,199 - INFO -   - Param shape: torch.Size([2048]), dtype: torch.float32
2025-04-25 19:08:21,200 - INFO -   - Copied. Param mean: 0.4637, std: 0.0852
2025-04-25 19:08:21,200 - INFO - Loading model.layers.21.post_attention_layernorm.weight:
2025-04-25 19:08:21,200 - INFO -   - Tensor shape: torch.Size([2048]), dtype: torch.bfloat16
2025-04-25 19:08:21,201 - INFO -   - Param shape: torch.Size([2048]), dtype: torch.float32
2025-04-25 19:08:21,201 - INFO -   - Copied. Param mean: 0.5546, std: 0.0391
2025-04-25 19:08:21,201 - INFO - Loading model.layers.21.self_attn.q_proj.weight:
2025-04-25 19:08:21,201 - INFO -   - Tensor shape: torch.Size([2048, 2048]), dtype: torch.bfloat16
2025-04-25 19:08:21,201 - INFO -   - Param shape: torch.Size([2048, 2048]), dtype: torch.float32
2025-04-25 19:08:21,271 - INFO -   - Copied. Param mean: -0.0000, std: 0.0238
2025-04-25 19:08:21,271 - INFO - Loading model.layers.21.self_attn.k_proj.weight:
2025-04-25 19:08:21,271 - INFO -   - Tensor shape: torch.Size([256, 2048]), dtype: torch.bfloat16
2025-04-25 19:08:21,271 - INFO -   - Param shape: torch.Size([256, 2048]), dtype: torch.float32
2025-04-25 19:08:21,292 - INFO -   - Copied. Param mean: 0.0000, std: 0.0395
2025-04-25 19:08:21,293 - INFO - Loading model.layers.21.self_attn.v_proj.weight:
2025-04-25 19:08:21,293 - INFO -   - Tensor shape: torch.Size([256, 2048]), dtype: torch.bfloat16
2025-04-25 19:08:21,293 - INFO -   - Param shape: torch.Size([256, 2048]), dtype: torch.float32
2025-04-25 19:08:21,302 - INFO -   - Copied. Param mean: -0.0000, std: 0.0259
2025-04-25 19:08:21,302 - INFO - Loading model.layers.21.self_attn.o_proj.weight:
2025-04-25 19:08:21,302 - INFO -   - Tensor shape: torch.Size([2048, 2048]), dtype: torch.bfloat16
2025-04-25 19:08:21,303 - INFO -   - Param shape: torch.Size([2048, 2048]), dtype: torch.float32
2025-04-25 19:08:21,369 - INFO -   - Copied. Param mean: -0.0000, std: 0.0191
2025-04-25 19:08:21,370 - INFO - Loading model.layers.21.mlp.gate_proj.weight:
2025-04-25 19:08:21,370 - INFO -   - Tensor shape: torch.Size([5632, 2048]), dtype: torch.bfloat16
2025-04-25 19:08:21,370 - INFO -   - Param shape: torch.Size([5632, 2048]), dtype: torch.float32
2025-04-25 19:08:21,567 - INFO -   - Copied. Param mean: -0.0000, std: 0.0243
2025-04-25 19:08:21,568 - INFO - Loading model.layers.21.mlp.up_proj.weight:
2025-04-25 19:08:21,568 - INFO -   - Tensor shape: torch.Size([5632, 2048]), dtype: torch.bfloat16
2025-04-25 19:08:21,568 - INFO -   - Param shape: torch.Size([5632, 2048]), dtype: torch.float32
2025-04-25 19:08:21,763 - INFO -   - Copied. Param mean: -0.0000, std: 0.0195
2025-04-25 19:08:21,764 - INFO - Loading model.layers.21.mlp.down_proj.weight:
2025-04-25 19:08:21,764 - INFO -   - Tensor shape: torch.Size([2048, 5632]), dtype: torch.bfloat16
2025-04-25 19:08:21,765 - INFO -   - Param shape: torch.Size([2048, 5632]), dtype: torch.float32
2025-04-25 19:08:21,957 - INFO -   - Copied. Param mean: 0.0000, std: 0.0180
2025-04-25 19:08:21,958 - INFO - Prepending BOS token (<s>) to prompt for encoding.
2025-04-25 19:08:21,958 - INFO - Initial Input IDs (with BOS): [529, 29879, 29958, 5618, 338, 278, 7483, 310, 3444, 29973, 829, 29879, 29958]
2025-04-25 19:08:21,959 - INFO - Starting generation loop (max_new_tokens=100, eos_token_id=2)
2025-04-25 19:08:22,553 - INFO - Step 1: Predicted token ID: 13
2025-04-25 19:08:22,997 - INFO - Step 2: Predicted token ID: 13
2025-04-25 19:08:23,464 - INFO - Step 3: Predicted token ID: 13
2025-04-25 19:08:23,893 - INFO - Step 4: Predicted token ID: 29966
2025-04-25 19:08:24,310 - INFO - Step 5: Predicted token ID: 465
2025-04-25 19:08:24,736 - INFO - Step 6: Predicted token ID: 22137
2025-04-25 19:08:25,173 - INFO - Step 7: Predicted token ID: 29958
2025-04-25 19:08:25,614 - INFO - Step 8: Predicted token ID: 13
2025-04-25 19:08:26,072 - INFO - Step 9: Predicted token ID: 1576
2025-04-25 19:08:26,503 - INFO - Step 10: Predicted token ID: 7483
2025-04-25 19:08:26,951 - INFO - Step 11: Predicted token ID: 310
2025-04-25 19:08:27,394 - INFO - Step 12: Predicted token ID: 3444
2025-04-25 19:08:27,953 - INFO - Step 13: Predicted token ID: 338
2025-04-25 19:08:28,430 - INFO - Step 14: Predicted token ID: 3681
2025-04-25 19:08:28,916 - INFO - Step 15: Predicted token ID: 29892
2025-04-25 19:08:29,384 - INFO - Step 16: Predicted token ID: 3444
2025-04-25 19:08:29,853 - INFO - Step 17: Predicted token ID: 338
2025-04-25 19:08:30,347 - INFO - Step 18: Predicted token ID: 278
2025-04-25 19:08:30,849 - INFO - Step 19: Predicted token ID: 7483
2025-04-25 19:08:31,366 - INFO - Step 20: Predicted token ID: 310
2025-04-25 19:08:31,860 - INFO - Step 21: Predicted token ID: 3444
2025-04-25 19:08:32,364 - INFO - Step 22: Predicted token ID: 338
2025-04-25 19:08:32,873 - INFO - Step 23: Predicted token ID: 278
2025-04-25 19:08:33,407 - INFO - Step 24: Predicted token ID: 7483
2025-04-25 19:08:33,942 - INFO - Step 25: Predicted token ID: 310
2025-04-25 19:08:34,470 - INFO - Step 26: Predicted token ID: 3444
2025-04-25 19:08:34,996 - INFO - Step 27: Predicted token ID: 338
2025-04-25 19:08:35,545 - INFO - Step 28: Predicted token ID: 278
2025-04-25 19:08:36,089 - INFO - Step 29: Predicted token ID: 7483
2025-04-25 19:08:36,641 - INFO - Step 30: Predicted token ID: 310
2025-04-25 19:08:37,202 - INFO - Step 31: Predicted token ID: 3444
2025-04-25 19:08:37,777 - INFO - Step 32: Predicted token ID: 338
2025-04-25 19:08:38,355 - INFO - Step 33: Predicted token ID: 278
2025-04-25 19:08:38,932 - INFO - Step 34: Predicted token ID: 7483
2025-04-25 19:08:39,524 - INFO - Step 35: Predicted token ID: 310
2025-04-25 19:08:39,535 - INFO - Step 36: Predicted token ID: 3444
2025-04-25 19:08:40,148 - INFO - Step 37: Predicted token ID: 29973
2025-04-25 19:08:40,747 - INFO - Step 38: Predicted token ID: 13
2025-04-25 19:08:41,343 - INFO - Step 39: Predicted token ID: 16066
2025-04-25 19:08:41,958 - INFO - Step 40: Predicted token ID: 29973
2025-04-25 19:08:42,577 - INFO - Step 41: Predicted token ID: 2
2025-04-25 19:08:42,578 - INFO - EOS token (2) generated. Stopping generation.
2025-04-25 19:08:42,578 - INFO - Full Generated Sequence IDs: [529, 29879, 29958, 5618, 338, 278, 7483, 310, 3444, 29973, 829, 29879, 29958, 13, 13, 13, 29966, 465, 22137, 29958, 13, 1576, 7483, 310, 3444, 338, 3681, 29892, 3444, 338, 278, 7483, 310, 3444, 338, 278, 7483, 310, 3444, 338, 278, 7483, 310, 3444, 338, 278, 7483, 310, 3444, 29973, 13, 16066, 29973, 2]
2025-04-25 19:08:42,579 - INFO - Full Decoded Text:
-------
<s>What is the capital of France?</s>


<assistant>
The capital of France is Paris, France is the capital of France is the capital of France is the capital of France is the capital of France?
France?
-------
2025-04-25 19:08:42,579 - INFO - Generated Part IDs: []
2025-04-25 19:08:42,579 - INFO - Generated Decoded Text:
-------

-------
2025-04-25 19:08:42,580 - INFO - Token IDs for <|system|>: [529, 29989, 5205, 29989, 29958]
2025-04-25 19:08:42,580 - INFO - Token IDs for <|user|>: [529, 29989, 1792, 29989, 29958]
2025-04-25 19:08:42,580 - INFO - Token IDs for <|assistant|>: [529, 29989, 465, 22137, 29989, 29958]
